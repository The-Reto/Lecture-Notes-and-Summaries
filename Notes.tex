\documentclass{report}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
%\usepackage[ngerman]{babel}
\usepackage{siunitx}
\usepackage{amsmath}   
\usepackage[version=3]{mhchem}
\usepackage[
    backend=biber,
    style=numeric,
  ]{biblatex}
\usepackage{physics}
\usepackage{amssymb}
\usepackage{tcolorbox}
\usepackage{mathtools}
\usepackage[margin=2cm]{geometry}

\newtcolorbox{redbox}[1]{colback=red!5!white,colframe=red!75!black,fonttitle=\bfseries,title=#1}
\newtcolorbox{greenbox}[1]{colback=green!5!white,colframe=green!75!black,fonttitle=\bfseries,title=#1}
\newtcolorbox{bluebox}[1]{colback=blue!5!white,colframe=blue!75!black,fonttitle=\bfseries,title=#1}
\newtcolorbox{graybox}[1]{colback=black!5!white,colframe=black!75!black,fonttitle=\bfseries,title=#1}
\addbibresource{sources.bib}
\graphicspath{ {/} }
\DeclareSIUnit \parsec {pc}
\DeclareSIUnit \lightyear {ly}
\DeclareSIUnit \year {yr}
\DeclareMathAlphabet{\mathpzc}{OT1}{pzc}{m}{it}

\title{10878 Physik der Kondensierten Materie\\
        \large Summary
        }
\author{Reto Fl√ºtsch}
\date{HS 2020}

\begin{document}

\maketitle
    
\chapter*{Introduction}
\section*{On this document}
This document are my personal notes on the lecture 10878 Physik der Kondensierten Materie at Uni Basel in the Fall semester 2020. I type this document during the lectures (while the Professors speak) with minimal editing between lectures - there are A LOT of spelling mistakes, typos and errors of various severity.
\section*{Information about this Course}
all lectures online, exercises online Tue 8:15 to 10:00 in two groups\\
nanophononics.physik.unibas.ch/pages/teaching.htm and adam will hold the presentations\\
Exercises 30 points per sheet 60\% of points required, hand in on thursday till 12am before lectures. Released on Friday. Links for exercise class will be sent by assistants.\\

Written exam on 20.01.2021 10:00 - 12:00, 5 pages double a4 handwritten notes and non-programmable calculator. Exam is based on exercise sheets. \\

Course mostly based on The Oxford Solid State Basics, Steven H. Simon. Some parts based on other books.


\tableofcontents
\newpage
\chapter{Heat in Solids}
\section{Introduction}
What is condensed Matter physics and why is it important? \\
We deal in solids and liquids Condensed: interactions between atoms win over entropy. Key question is how to reproduce the properties of matter which is a many body problem. Currently the largest subfield of Physics.\\

Intro question: \emph{Which keeps coffee warmest?}
\begin{itemize}
	\item Steel Cup \\
	\item Ceramic Cup \\
	\item Glass Cup 
\end{itemize}
The Steel cup looses, electrical conducters are also good thermal conductors. Glass acctually has the lowest thermal conductivity, yet the ceramic cup still wins. Why? \\
It's not only the thermal conductivity that matters, it's also the heat capacity that matters, and in this regard ceramics are almost unbeatable.\\
\subsection{Heat Capacity - Definitions}
Heat Capacity is how much heat can you store in a material per change in temperature. \[
C = \frac{\partial U}{\partial T}
.\] Specific heat $c_v$ is the heat capacity per unit volume. $C_{N_a}$ is the heat capacity per mole, as it's otherwise per atom. \\
We will only deal with the Heat Capacity at constant presure and volume. \[
C_P \approx C_V = C
.\] We will now derive the Heat Capacity in a solid from the Heat Capacity in a Gas \[
\frac{C_V}{N} = \frac{3}{2} K_B \text{ for a momo-atomic gas}
.\]
Multiplying by $N_A$ yields: $C_V = \frac{3}{2} R$.
\section{Dulong-Petit}
Purely observational law for many solids: \[
C = 3 K_B \text{ per atom}
\] \[
C = 3 R
.\] Works pretty well for many materials at room temperature (notable exception is Diamond).\\
Where did the law for Gas come from? Equipartition system, each degree of freedom gets equal amount of the internal energy $\frac{1}{2} K_B T$. In a Gas there are $3$ degrees of Freedom (three elements of momentum). \\
For solids there are an additional $3$ degrees of freedom from the potential energy (positional degrees of freedom) \[
3 \text{ degrees of freedom from kinetic energy} + 3 \text{ degrees of freedom from potential energy}= 6 \text{ degrees of freedom}
.\] \[
U = \frac{3+3}{2} K_B T
.\] \[
C = \frac{\partial U}{\partial T} = 3 K_B \text{ per atom}
.\]  \[
\implies C = 3 R \text{ per mole}
.\] 
This 'law' fails for very low temperatures for all materials, and for some (notably diamond) it even fails completely.
\section{Einstein Model}
Assumes the particles are oscilating around their positional groundstate, and uses the expectation value of the potential energy instead of its' groundstate energy.\\
We assume the atoms are in a harmonic potential well and behave like harmonic oscilators with energy eigenstaten $E_m = \hbar \omega \left( n + \frac{1}{2} \right) $. (Einstein did not include the factor $+ \frac{1}{2}$ as QM was not yet dicovered). \\
We introduce the \emph{Partition Function} $Z$, which describes the distribution among all possible microstates of a system. This function is extremly important in statistical mechanics and can be used to derive most macroscopic properties. It is given by: \[
	Z = \sum_{n=0}^{\infty} \exp\left( -\beta E_n \right) 
.\] With $\beta = \frac{1}{K_BT}$. \\
We can use the partition function for example to calculate the probability to find a system in a certain microstate as $P(E_n) = \frac{\exp\left( -\beta E_n \right)}{Z} $. We can thus write the expectation value of the energy as \[
	<E> = \sum_{n=0}^{\infty} P\left( E_n \right) E_n = \frac{1}{Z} \sum_{n=0}^{\infty} E_n \exp\left( -\beta E_n \right) 
.\] Looking at this result we realize that \[
\frac{\partial Z}{\partial \beta} = \sum_{n=0}^{\infty} -E_n \exp\left( -\beta E_n \right) 
\] \[
\implies <E> = -\frac{1}{Z} \frac{\partial Z}{\partial \beta}
.\] This is the more general form of the energy expectation in terms of the partition function. \\
For the harmonic oscilator where $E_n = \hbar \omega \left( n + \frac{1}{2} \right) $ we therefore get: \[
	Z = \sum_{n=0}^{\infty} \exp\left( -\beta \hbar \omega \left( n + \frac{1}{2} \right)  \right) 
\] \[
= \exp\left( -\frac{\beta \hbar \omega}{2} \right) * \sum_{n=0}^{\infty} \exp\left( -\beta \hbar \omega n \right) = \exp\left( \frac{-\beta \hbar \omega}{2} \right) * \sum_{n=0}^{\infty} \exp\left( -\beta \hbar \omega \right) ^n
\] we recognize a geometric series and rewrite \[
Z = \exp\left( -\frac{\beta \hbar \omega}{2} \right) * \frac{1}{1- \exp\left( -\beta \hbar \omega \right) } = \frac{1}{\exp\left( \frac{\beta \hbar \omega}{2} \right) + \exp\left(-  \frac{\beta \hbar \omega}{2} \right) } = \frac{1}{2 \sinh\left( \frac{\beta \hbar \omega}{2} \right) }
.\] For the energy expectatation value we thus get \[
<E> = -\frac{1}{Z} \frac{\partial Z}{\partial \beta} = - \frac{\hbar \omega}{2} \coth\left( -\frac{\beta \hbar \omega}{2} \right) 
.\] Introducing the \emph{Bose occupation factor} $n_B(x) = \frac{1}{\exp\left( x \right) -1}$ we get \[
<E> = \hbar \omega \left( n_B\left( \beta \hbar \omega \right) + \frac{1}{2} \right) 
.\] In this calculation we have only considered a one-dimensional harmonic oscilator, in reality we have to consider the three-dimensional case. In three dimensions the expectation value for the energy is three times higher \[
<E_{3d}> = 3 <E_{1d}> = 3 \hbar \omega \left( n_B\left( \beta \hbar \omega \right) + \frac{1}{2} \right) 
.\] According to definition the Heat capacity is given by \[
c = \frac{\partial <E>}{\partial T} = K_B \left( \beta \hbar \omega \right) ^2 \frac{\exp\left( \beta \hbar \omega \right) }{\left[ \exp\left( \beta \hbar \omega \right) -1  \right] ^2}
.\] We will now investigate this new expression in the limit for very big and very small temperatures: \[
\lim_{T \to \infty} c = \lim_{\beta \to 0} c = 3K_B \text{ for big temperatures we recover the Dulong-Petit Law as expected}
\]  \[
\lim_{T \to 0} c = \lim_{\beta \to \infty} c = 0 \text{ for very small Temperatures the model predicts an exponential decay.}
\] 
This approximation models all materials at high and low temperatures, but still fails at very low temperatures, where it predicts a exponential decay, where in experimets a decay $\propto T^3$ is measured.
\section{Debye Model of Solids}
Assumes that atoms at the bottom of their potential well oscillate not independently from each other, but are coppeled in a collective motion. Simmilar to sound waves. \\
QM was not yot discovered, but the quantisation of light was known, Debye thus applied that same line of thinking to sound waves. It's important to note, that soundwaves, contrary to lightwaves can also have a longitudional part.\\
We will treat waves in a finite solid with periodic boundary conditions. We define a periodic space onwhich there is a periodicity such that all waves are same at $x=0$ and $x=L$. Thus only wavelength of the foarm \[
\lambda_m = \frac{2L}{m} \text{ are allowed}
.\] The Wavelengths of the 'allowed' waves are given by \[
K = \frac{2\pi m}{L}
.\] Whenever we want to treat the sum over 'all possible' values of $k$ we can replace the sum over all $k$ with an integral (provwided that $L$ is big) \[
\sum_{k} \to \frac{L}{2\pi} \int_{-\infty}^{\infty}dk
.\] In three dimensions this integral is over the three dimensional $k$-space \[
\sum_{k} \to \left( \frac{L}{2\pi}^3 \right) \int d^3k
.\] \\
Debye assumed that the oscillation modes in a solid behave like sound waves, and therefor have a linear dispersion relation \[
	\omega(k) = v \abs{k}
.\] The only adaptation to Einstein we have to do, is to integrate over all possible $k$.
\[
	<E> = 3 \sum_{k} \hbar \omega(\vec{k}) \left( n_B(\beta \hbar \omega(\vec{k})) + \frac{1}{2} \right) 
.\] \[
\implies <E> = 3 \frac{L^3}{\left( 2\pi \right) ^3} \int \hbar \omega(\vec{k}) \left( n_B(\beta \hbar \omega(\vec{k})) + \frac{1}{2} \right) d\vec{k}
.\] By switching to spherical coordinates we get $\int d\vec{k} \to 4\pi \int_0^{\infty} k^2 dk$ \[
\implies <E> = \frac{3(4\pi)L^3}{(2\pi)^3} \int_0^{\infty} k^2 \hbar \omega \left( n_B(\beta \hbar \omega) +\frac{1}{2} \right) 
.\] We now use the dispersion relation and insert $\omega = vk$ \[
\implies v dk = d\omega \text{ and } k^2 = \frac{\omega^2}{v^2}
.\] \[
\implies <E> = 3 \frac{4 \pi L^3}{(2\pi)^3} \int_0^{\infty} \omega^2 \frac{1}{v^3} \hbar \omega \left( n_B(\beta \hbar \omega) + \frac{1}{2} \right) d\omega
.\] If a solid has $n$-atoms per unit volume then a cube of side $L$ has a total of $N$ atoms. $\to N = n L^3 \implies L^3 = \frac{N}{n}$. \[
\implies <E> = \int_0^{\infty} \left( \frac{12 \pi \omega^2 N}{ (2 \pi)^3 n} \right) \frac{1}{v^3} \hbar \omega \left( n_B(\beta \hbar \omega) + \frac{1}{2} \right) d\omega 
.\] 
 If we define the density of States as \[
	 g(\omega) = N \left( \frac{12 \pi \omega^2}{\left( 2 \pi \right) ^3 n v^3} \right) 
 .\] We can rewrite the energy expectation as \[
 <E> = \int_0^{\infty} g(\omega) \hbar \omega \left( n_B(\beta \hbar \omega) + \frac{1}{2} \right) 
 .\] The density of states $g(\omega)$ is a factor weighing ow many states that there are at a given frequency. The Integral is thus just equal to the density of the states times the energy of the states at a given frequencyp.\\
 If we further define a Debye frequency $\omega_D = 6 \pi^2 n v^3$ we can further simplify the density $g(\omega) = N \frac{9 \omega^2}{\omega_D^3}$. \\
 The final result for the energy expectation is thus: \[
	 <E>_{tot} = \frac{9 N \hbar}{\omega_D^3} \int_0^{\infty} \frac{\omega^3}{\exp\left( \beta \hbar \omega \right) - 1} d\omega
 .\] Note: we have left out the factor of $\frac{1}{2}$, because we will differentiate later and it'd fall out anyway (also leaving it in creates unnecessary mathematical difficulties).\\
 To solve the integral we make a change of variables \[
 x = \beta \hbar \omega \to \frac{dx}{\beta \hbar} = d\omega
 .\] The solution is still very tedious, the final result is given by \[
 <E> = 9N \frac{(K_BT)^4}{(\hbar \omega_D)^3} \left( \frac{\pi^4}{15} \right) 
 .\] We therefore get \[
 C = \frac{\partial <E>}{\partial T} = \ldots \propto T^3
 .\] Debye thus correctly models the low temperature regime ($T^3$ dependence) but fails for high temperatures, and does not converge to the Dulang-Petit. \\
 The problem of the Debye model is that we were integrating over an infinite number of modes, but in reality there can never be an infinite amount of modes. \[
	 \text{No. of modes} = \int_0^{\infty} g(\omega) \to \infty
 .\] Debye thus introduced a 'cutoff frequency' such that the total number of modes are equal to the total number of degrees of freedom \[
 3N = \int_0^{\omega_{cutoff}} g(\omega)d\omega
 .\] With this correction we get \[
 <E> = \int_0^{\omega_c} g(\omega) \hbar \omega n_B(\beta \hbar \omega) d\omega
 .\] At high temperatures we thus get: \[
 T \to \infty \implies n_B(\beta \hbar \omega) \to K_B \frac{T}{\hbar \omega}
 .\] \[
 \implies <E> = K_B T \int_0^{\omega_c} g(\omega) d\omega = 2 K_B T N 
 .\] \[
 \implies C = 3NK_B = 3R \text{ (Dulang-Petit!)}
 .\] It's a bi tad-hoc, but it works.\\
 We acctually find that the cutoff frequency is equal to the Debye frequency \[
	 \omega_{cutoff} = \omega_D
 .\] 
The final result of Debye is thus: \[
	<E>_{tot} = \int_0^{\omega_c} g(\omega) \left( n_B(\beta \hbar \omega) + \frac{1}{2} \right) 
.\] 
The Debye model is the first model that does not feature a fitting parameter. Unfortunatelly there are still some problems:
\begin{itemize}
	\item $\omega_{cutoff}$ is an unexplained ad hoc correction
	\item The dispersion relation used $\omega = vk$ does not hold at high temperature
	\item There are still some exotic material that are not modelled cerrectly
	\item For metals the heat capacity $c$ at low temperatures is different: $c \propto \alpha T^3 + \gamma T$. \\
		Only the $T^3$ dependence is moddeled correctly by the Debye model.
\end{itemize}

\chapter{Drude Theory}
Developed three years after the discovery of electrons. To accurately describe metals we have to take the electron $e^-$ into account. \\
Drude applies the kinetic theory of Bolzman to electrons, a few assumptions are neccesary: 
\begin{itemize}
	\item There are collisions among electrons with a scattering time $\tau$. The probability of scattering is given by $\frac{dt}{\tau}$
	\item After scattering the momentum $\vec{p}_{final} = 0$. This obviously only holds on average across many collisions
	\item If there are electric and magnetic fields $\vec{E}$ $\vec{M}$ the electrons will interact with them
\end{itemize}
While assumptions 1 and 3 are also valid in gasses, the third assumption obviously only holds for electrons.
\section{Relaxation Time Approximation}
We consider a electron traveling through a cristal with momentum $\vec{p}$. After some time a scattering event occures, after this event it has a new momentum $\vec{p}\left( t + \delta t \right) $.
We first consider all the electrons that collide in the time $\delta t$. The probability is given as $\frac{\delta t}{\tau}$, according to the second assumption, those electrons will end up with $\vec{p}=0$.\\
Electrons that don't collide. The probability of no collision is given as $1 - \frac{\delta t}{\tau}$. When an electron does not collide, it will accelerate due to the force acting on it $\vec{F} = m_e a = \frac{d \vec{p}}{dt}$. The force can naturally vary with time $\to \vec{F} + O(t)$. \[
	\implies \delta\vec{p} = \vec{F} \delta t + O\left( \delta t^2 \right) 
.\] What we search is $\vec{p}\left( t + \delta t \right) $. \[
\vec{p}\left( t+ \delta t \right) = \frac{\delta t}{\tau} \vec{p}_{final} + \left( 1-\frac{\delta t}{\tau} \right) \left[ \vec{p}(t) + \vec{F}(t)\delta t + O\left( \delta t^2 \right)  \right]
.\] The first term is $0$ because of assumption 2 \[
\implies \vec{p}\left( t + \delta t \right) = \left( 1- \frac{\delta t}{\tau} \right) \left[ \vec{p}(t) + \vec{F}(t) \delta t \right) = \vec{p}(t) + \vec{F}(t) \delta t - \frac{\delta t}{\tau}\vec{p}(t)
.\] \[
\implies \frac{d\vec{p}(t)}{dt} = \vec{F} - \frac{\vec{p}(t)}{\tau}
.\] This result is called the relaxation time equation of the drude model. We know that \[
\vec{F} = -e\left( \vec{E} + \vec{v} \cross \vec{B} \right) 
.\] The other term $\vec{p}/\tau$ can be understood as a kind of drag on the electrons.\\
As an example we consider $\vec{F} = 0$ and get \[
	\frac{d\vec{p}(t)}{dt} = - \frac{\vec{p}(t)}{\tau} \implies \vec{p}(t) = \vec{p_0} \exp\left( - \frac{t}{\tau} \right) 
.\] 
On average the momentum $\vec{p}$ tends to zero (due to scattering) in absence of no external force $\vec{F}$.\\
\section{$e^-$ in electric fields - Drude conductivity}
We recall ohm's law $\vec{j} = \sigma \vec{E}$. We assume that we have $\vec{E} \neq 0$ but $\vec{B} = 0$ $\implies \vec{F} = -e\vec{E}$. We thus get \[
	\frac{d\vec{p}}{dt} = -e \vec{E} - \frac{\vec{p}}{\tau}
.\] We are interested in a steady state $\frac{d\vec{p}}{dt}=0$ \[
\implies \vec{p} = -e \tau \vec{E} = m \vec{v}
.\] \[
\implies \vec{v} = -\frac{e\tau}{m_e}\vec{E}
.\] We now use ohm's law with current density $\vec{J} = -ne\vec{v}$, with the electron density $n$. \[
\vec{J} = -ne\vec{v} = -ne\left( - \frac{e\tau}{m_e} \vec{E} \right) = \frac{n e^2 \tau}{m_e} \vec{E} = \sigma \vec{E}
.\] \[
\implies \sigma_{drude} = \frac{ne^2\tau}{m_e}
.\] 
The conclusion of this part, is that if you can measure $\sigma_{drude}$ you can use it to measure the electron density in a material.
\section{$e^-$ in $\vec{E}$ and $\vec{B}$ - Hall effect in the Drude model}
\[
	\vec{F} = -e\left( \vec{E} + \vec{v} \cross \vec{B} \right) 
.\] \[
\implies \frac{d\vec{p}}{dt} = - e\left( \vec{E} + \vec{v} \cross \vec{B} \right) - \frac{\vec{p}}{\tau}
.\] Again we are interested in the steady state. \[
-e\vec{E} - e \vec{v}\cross \vec{B} - \frac{\vec{p}}{\tau} = 0
.\] \[
\implies -e\vec{E} + \frac{\vec{J} \cross \vec{B}}{n} + \frac{m_e}{ne\tau}\vec{J} = 0
	.\] We assume that $\vec{B} = -B_z \vec{e_z}$. We then take a piece of metal with dimensions $L_x$, $L_y$, and $L_z$, and run a current trough the metal aleng the $X$-axis a $\implies \vec{J} = J_x \vec{e_x}$, thus we also know that $\vec{E} = E_x \vec{e_x} + E_y \vec{e_y}$ will only have components in the X/Y-Plane.
\[
	\text{X component: } eE_x = 0 + \frac{m_e}{ne\tau}J_x \implies E_x = \frac{m_e}{ne^2\tau}J_x				
\] \[
\text{y component: } eE_y = \frac{J_x B_z}{n} + 0 \implies E_y = \frac{B_z J_x}{n e}
.\] \[
\text{z component: } 0 = 0 + 0
.\] We know that $\vec{J} = \sigma \vec{E} = \frac{1}{\rho} \vec{E}$ but we now see that the restance $\rho $ depends on the direction (aka. is a matrix). \[
\rho_{x x} = \frac{E_x}{J_x} = \frac{ne^2 \tau }{m_e}
\]\[
\rho_{x y} = \frac{E_y}{J_x} = - \frac{B}{n e}
\] The really important coefficient is $\rho_{x y}$ (the longitudinal resistivity $\rho_{x x}$ is expected). We call $\rho_{x y}$ the Hall resistivity, which means that there is a voltage along Y that we call Hall voltage. \\
The Hall effect thus is the effect, that when applying a magnetic field pependicular to a current density we suddenly measure a voltage perpendicular to both. This effect is used for a variety of measurements.\\
We define the Hall coefficient:  \[
	R_H = \frac{\rho_{xy}}{ |B| } = - \frac{1}{ne}
.\] How can the Hall effect can acctually be used? 
\begin{itemize}
	\item Hall sensors to measure magnetic fields $\vec{B}$.\\
		If $n$, $e$ and $\vec{J}$ are known we can use the Hall effect to measure a magnetic field. Note: High Hall voltages are easier to measure, for such sensors we want to choose materials with a big Hall coefficient $R_H = -\frac{1}{ne}$, aka. with small $n$ (semiconductors).
	\item If we know $\vec{B}$ and $\vec{J}$ we can measure the electron density.
\end{itemize}
\section{Heat Capacity due to $e^-$}
We study a cylinder that we are heating on one end. There will be a heat flow $\vec{Q}$ and a heat flux, or heat current density, $\vec{J}_Q = \frac{\text{energy}}{\text{time} * \text{area}}$.\[
J_Q = - \kappa \grad T
.\] Druede assuemes that the heat in metals is only transported by the electorns, and he describes electrons with the kinetic theory of gasses. \[
\kappa = \frac{1}{3} n C <v> \lambda = \frac{1}{2} n c <v>^2 \tau
.\] With $\lambda = <v> \tau$ the distance an electron will travel before scattering. From the last Lecture we know that $\frac{C}{N}= \frac{3}{2} K_B$. We also know an expression for the velocity $<v^2> = \frac{3K_BT}{m_e}$ \[
\implies \kappa = n \frac{3}{2} \frac{K_B^2T}{m_e} \tau
.\] Note: we assumed $<v^2> = <v>^2$ which does not hold generally and will lead to problems later on. The question now is: how do we find $\tau$?\\
From earlier we know $\sigma_{Drude} = \frac{ne^2\tau}{me}$ we thus consider \[
	\text{Lorenz number: } L_{Drude} = \frac{\kappa}{\sigma T} = \frac{3}{2} \left( \frac{K_B}{e} \right)^2 \frac{1}{T}
.\] We call the ratio between $\kappa$ and $\sigma$ the Wiedeman-Franz ratio \[
\frac{\kappa}{\sigma} = \frac{3}{2} \left( \frac{K_B}{e} \right) ^2
.\] The Wiedeman-Franz law states that \[
LT = \frac{\kappa}{\sigma}
.\] Thus we know that in metals thermal conductivity $\kappa$ and electircal conductivity $\sigma$ are proportional to each other. The interisting thing is that the Lorenz number has another definition \[
L = \frac{\pi^2 K_B^2}{3 e^2} \approx 2*L_{Drude}
.\] Even with the factor of $2$ the Drude model is still a success because previously it was unexplained why the Wiedeman-Franz law even holds (previously it was only known experimentaly). The exact value of the Lorenz number given above comes from modern quantum mechanical calculations.
\section{Thermoelectric Properties - how the Drude model fails}
Conversion of Heat into electricity. Electrical currents always carry heat. But an electrical current is always heating the conducter via Joule heating $I^2R$, for use in thermoelectric devices one wants to minimize $R$.\\
\[
\Delta V=S \Delta T  \text{  with $S$ the Seekech coefficient}
.\] \[
Q = \Pi I \text{  with $\Pi$ the Peltier coefficient}
.\] We get the relationship \[
\vec{J_q} = \Pi \vec{J}
.\] With $\vec{J_q}$ the heat current density and $\vec{J}$ the electrical current density. We already know: \[
\vec{J} = -e n \vec{v}
\] \[
\implies \Pi = \frac{J_q}{J} = - \frac{1}{3} \frac{C_v T}{e} = - \frac{C_v T}{3e} = - \frac{K_B T}{2 e}
.\]  There is also an expression for $S$ the Seebeck coefficient \[
S= \frac{\Pi}{T} = - \frac{K_B}{2e} = -4.3 * 10^{-4} \frac{\text{V}}{\text{K}}
.\] But the real values of $S$ are on the order of $\propto 10^{-6} \frac{\text{V}}{\text{K}}$. We now found a significant failure of the Drude system. But why did it work so well for the heat capacity but fails so badly for thermoelectircal effects?\\
Drude commited two errors, that cancelled eachother out in the case of the heat capacity.
\begin{itemize}
	\item He assumed $<v>^2 = 3 \frac{K_B T}{m_e} \gg \text{ acctual } <v>^2$ 
	\item He assumed $\frac{C_v}{N} = \frac{3}{2} K_B \gg $ the acctual heat capacity
\end{itemize}
\section{Success and Failures of the Drude model}
\subsection{Mean free path of $e^{-}$ - $\lambda$ }
\[
\lambda = <v> * \tau
.\] \[
\sigma = \frac{ne^2\tau}{m_e}\text{ ,  } \rho = \frac{1}{\sigma}
.\] $\rho$ can be measured in materials and can thus be used to measure $\tau$.  \[
\implies \tau = \frac{m_e}{ne^2\rho} \approx 1 \text{ - } 10 \text{fs}
\] \[
<v> \approx \sqrt{\frac{2K_B T}{m_e}} 
\] \[
\implies \lambda = <v> \tau \approx 0.1 \text{ - } 1 \text{nm}
.\]  Close to the lattice constants in materials $\to $ success of Drude.
\subsection{Measured Values}
With the Hall effect we can measure the electron density \[
n = -\frac{1}{eR_H}
.\] We can now compare the values measured electron density to the theoretical values for the electron density. We call the density of atoms in a solid $n_a$. For monovalent atoms (with only one atom in the valence shell) we find  \[
n_a = n
.\] We can infere a general quantity $\alpha = \frac{n}{n_a}$. For Valence $= 1 \implies \alpha = 1$, for valence $V \implies \alpha = V$.\\
When we compare the known valence of various Metals to the theoretically measured $\alpha$ 's we find a good match for Li or Ne (with a valence of $V = 1$ ), but fails for elements with $V > 1$.\\
The Drude model works pretty well for monovalent atoms, but fails for higher valence atoms (sometimes even getting the sign of $\alpha$ wrong).\\
Other successes: 
\begin{itemize}
	\item $\delta T$ respects the Wiedemann-Franz law (with only an error factor of $2$ )
\end{itemize}
Other failures:
\begin{itemize}
	\item Seebeck coefficient is too big (by two orders of magnitude).
\end{itemize}

\chapter{Sommerfeld Theory for free electrons in metals}
The mistake of Drude, was that he applied the kinetic theory of gasses (based on Bose-Einstein statistics) to electrons. He thus implicitly assumed electrons to be bosons, bu they are fermions.\\
\section{Fermi-Dirac Statistics}
Historical context
\begin{itemize}
	\item 1925: Pauli exclusion principle (two $e^{-}$ cannot be in the exact same state)
	\item 1926: Schroedinger Equation and Fermi-Dirac statistics
	\item 1927: Sommerfeld applies FD statistics to metals
\end{itemize}

We have to define a Fermi occupation function $n_F\left( \beta(\epsilon - \mu \right) = \frac{1}{\exp\left( \beta(\epsilon - \mu) \right) + 1 } $. It's the probability that the fermion occupies a state with energy $\epsilon$. $\mu$ is the chemical potential, is defined by the Fermi occupation function.\\
We use this Fermi occupation function $n_F$ instead of the Bose-Einstein occupation function $n_B$.\[
	n_B = \frac{g_i}{\exp\left( \frac{\left( \epsilon_i - \mu \right) }{K_BT} \right) -1} \text{ with $g_i$ the states degeneracy}
.\] \[
n_F = \frac{1}{\exp\left( \frac{\epsilon_i - \mu}{K_B T} \right) +1}
.\] Fermi Statistics cannot allow for degeneracy, since fermions can \emph{never} be in the exact same state. We have to differentiate Bosons (indistinguishable quantum particles) and Fermions (distinguishable quantum particles).
Sommerfeld used FD and quantum mechanics to desciribe the electrons in a metal as a "Fermi-Gas". He does two upgrades to the Drude Model:
\begin{itemize}
	\item calculates the energy quantum mechanically
	\item usese FD statistics
\end{itemize}
\section{Quantum States of $e^{-}$ in solids}
We consider a solid with regularly spaced atoms and look at the potential. The real potential is complicated so Sommerfeld made some approximations
\begin{itemize}
	\item He neglected core electrons and considered only valence electrons.
	\item He replaced the true coulomb-potential with a constant, average, potential $V_0$.
	\item He ignored interactions between electrons.
	\item He assumes that the surface of the solid act like a barrier of height $\infty$.
\end{itemize}

With these approximations we can write the Schroedinger Equation in 1d: \[
	\frac{\hbar^2}{2m_e} \frac{\partial^2}{\partial x^2} \psi(x) = V \psi(x)
\] Because of the assumption that the surface of the solid has a potential of $V_{boundary} = \infty$ we get the boundary conditions  \[
\psi(0) = \psi(L) = 0
\] \[
\implies \psi(x) = A \sin\left( k_x x \right) 
.\] We get standing waves with $k_x = \frac{2\pi}{L} n_x$ with $n_x \in \mathbb{Z}$.  
We get the Energy of a state as \[
	E_n = \frac{\hbar^2 k_{x\text{,}n}^2}{2 m_e} = \frac{\hbar^2 4 \pi^2 n_x^2}{2 m_e L}
.\] 
We have a discrete, quadratic potential. The energy entierly determined by the quantum number $n_x$.\\
According to the Pauli exclusion principle each electron has to have unique quantum numbers. There are multiple quantum numbers, they are
\begin{itemize}
	\item $n_x$, $n_y$, and $n_z$ 
	\item spin number $n_s = \pm \frac{1}{2}$
\end{itemize}
We know that if two electrons have the same energystate (given by $\vec{n}$ ) must have opposite spin.
Every value of the three energy state numbers ($\vec{n}$ ) can hold two electrons (one with spin 'up' and one with spin 'down'). \\
\section{Filling the $k$-space with electrons}
We now consider the $K$-space, in which only discrete values are allowed. We know that the spacing between the allowed values in the $i$-axis is given by $\frac{2\pi}{L_i}$, with $L_i$ the length of the solid in the $i$-axis.\\
The area of a discrete value in a two dimensional $K$-space is given by \[
	A = \frac{2\pi}{L_x} \frac{2\pi}{L_y} = \frac{\left( 2\pi \right) }{L_x L_y}
\] In 3d we get a volume \[
V = \frac{\left( 2\pi \right) ^3}{L_x L_y L_z}
.\] We consider a two dimensional system and lable the $K$-states \[
K_x = \left( \frac{2\pi}{L_x} \right) n_x \text{        } K_y = \left( \frac{2\pi}{L_y} \right) n_y
\] \[
E = \frac{\hbar \vec{K}^2}{2 m_e} = \frac{\hbar^2}{2 m_e} \left( K_x^2 + K_y^2 \right) = \frac{\hbar^2 \left( 2\pi \right) ^2}{2 m_e} \left( \frac{n_x^2}{L_x^2} + \frac{n_y^2}{L_y^2} \right) 
.\] We thus have to fill the K-space from the center outwards, up to a certain maximum $\vec{K_F}$, that we call Fermi $K$-Vector. We have to choose $\vec{K_F}$ such that we can fill the sphere in the $K$-space with radius $|\vec{K_F}|$ with all of our electrons. \[
E= \frac{\hbar^2 K^2}{2m_e} \implies E_F = \frac{\hbar^2 \vec{K_F}^2}{2m_e} \text{ Fermi energy}
.\] We thus get a sphere containing allowed energy states, we call this sphere \emph{Fermi Sphere}, the maximum allowed energy in this Fermi Sphere is the Fermi Energy $E_F = \frac{\hbar^2 \vec{K_F}^2}{2 m_e}$. \\
No matter what dimensionality our problem has, we can define the Fermi Sphere and get the occupation probability \[
	n_F = \frac{1}{\exp\left( \frac{E - E_F}{K_B T} \right) + 1}
.\] At $T =0$ this probability is a step-function with $n_F = 1 \forall E < E_F$ and $n_F = 0 \forall E > E_F$. For any other temperatures the step function is 'smoothed' out and we get $n_F = \frac{1}{2} $ at $E = E_F$.
\subsection{Fermi-Energy, -Wavevector and -surface}
We assume that there are $N$ electrons in our system. \[
	N = 2* \sum_{\vec{k}} n_{FD}\left( E \right) = 2 \frac{V}{\left( 2 \pi \right) ^3} \int n_{FD} d\vec{k}
.\] We know that at $T = 0 \text{K}$ the Fermi-Drirac function is a step function \[
n_{FD} \left( E \right) = 1 \forall E \le E_F \text{, } 0 \text{ otherwise}
.\] \[
\implies N = 2 \frac{V}{\left( 2 \pi \right)^3} \int_0^{K \le K_F} dK
\] \[
= \frac{2V}{\left( 2 \pi \right) ^3} * \frac{4}{3} \pi K_F^3
.\] We would like to know the electron density $n = \frac{N}{V}$ \[
\implies n = \frac{N}{V} = \frac{K_F^3}{3 \pi^2}
.\] We can use this fact to easily calculate $K_F$ and thus the Fermi-Energy from the electron density. 
\[
	K_F = \left( 3 \pi^2 n \right) ^{\frac{1}{3}}
.\] 
\subsection{Fermi-Momentum and Velocity}
We define the Fermi-velocity via:
\[
	\vec{P} = \hbar \vec{K_f} = m_e \vec{v_F}
\]\[
V_f = \frac{\hbar}{m_e} \left( 3 \pi^2 n \right) ^{\frac{1}{3}}
.\] For typical electron densities we find $v_F \approx 0.5 \text{ to } 1\% C$ with $C$ the speed of light. 
We know \[
	E_F = \frac{\hbar^2 K_F^2}{2m_e} = \frac{\hbar^2}{2 m_e} \left( 3 \pi^2 n \right) ^{\frac{2}{3}}
.\] from this we find the Fermi-Temperature \[
T_F = \frac{E_F}{K_B}
.\] For typical metals the Fermi-Temperatures we find is somwhere between $6*10^4$ K and $10^5$ K.
\subsection{Average Energy of an electron in a Fermi-Gas}
To get the average energy we first calculate the total energy of our system: \[
	E_{tot} = 2 \int_0^{K\le K_F} \frac{V}{(2\pi)^3} \frac{\hbar^2 k^2}{2 m_e} d^3k
\] \[
= \frac{\hbar^2 V}{\left( 2 \pi \right) ^3 m_e} \int_{06}{K_f} k^2 d\vec{K}		
.\] Substituting $d\vec{K} = 4\pi k^2 dk$ (our $\vec{K}$ are packed in a sphere, over which we integrate) \[
= \frac{\hbar^2 V}{\left( 2 \pi \right) ^3 m_e} 4\pi \int k^4 dk = \frac{\hbar^2 V}{2 \pi^2 m_e} \frac{1}{5} K_F^5
\] \[
E_{tot} = \frac{\hbar^2 V}{10\pi^2 m_e}K_F^5
.\]  

Using \[
N = \frac{2V}{\left( 2\pi \right) ^3} \frac{4}{3} K_F^3
\] 
the average energy $E_{avg}$ is given by \[
	\frac{E_{tot}}{N} = \frac{3}{5} \frac{\hbar^2}{m_e}K_F^2 = \frac{3}{5}E_F
.\] 
\section{Density of States}
$g$ is the number of (quantum) states for electrons per unit volume and per unit energy. We can define the density of electrons at a porticular energy and temperature as \[
	n\left( E\text{, }T \right) = \frac{g(E)}{V} f\left( E_F\text{, }T \right) 
.\] With $f\left( E\text{, }T \right) $ the Fermi-Dicrac distribution. \\
As defined above $g(k)$ is the number of $k$-states per total volume. We can now write \[
	g(E)dE = g(k)d^3k = \left( \frac{L}{2\pi} \right) ^3 d^3k
\] We also know already \[
E = \frac{\hbar^2 k^2}{2 m_e} \implies k = \sqrt{\frac{2m_e}{\hbar^2}E} \implies dk = \sqrt{\frac{2m_e}{\hbar^2}E} \frac{1}{2} dE
.\] \[
\implies g(E) dE = \left( \frac{L}{2\pi} \right) ^3 4\pi k^2 dk
\] \[
= \left( \frac{L}{2\pi} \right) ^3 4\pi \frac{2m_e E}{\hbar^2} \sqrt{\frac{2m_e}{\hbar^2} E} \frac{1}{2} dE
\] \[
\implies g(E) = \frac{V}{\left( 2\pi \right) ^2} \left( \frac{2 m_e}{\hbar^2} \right) ^{\frac{3}{2}} \sqrt{E} 
.\] $g(E)$ per volume is thus given by \[
\frac{g(E)}{V} = \frac{1}{\left( 2\pi \right) ^2} \left( \frac{2m_e}{\hbar^2} \right) ^{\frac{3}{2}} \sqrt{E} = \frac{3}{2} \frac{n}{E_F} \sqrt{\frac{E}{E_F}}  
.\] The key takeaways here are that $g(E) \propto \sqrt{E} $ and that \[
g(E_F) = \frac{3}{2} \frac{n}{E_F}
.\]   
\section{Electronic Heat Capacity}
We now want to calculate the contribution of the electrons to the Heat Capacity. In a gas of electorns we wauld expect $U_{el} = 3 * \frac{1}{2} K_B T \implies c_{el} = \frac{3}{2}K_B$ per electron. But in a fermi-gas only the electrons close to the Fermi-surface can acctualy "gain" internal energy and contribute to the heat capacity. \\
A fermigas will thus "accept" heat in a very different way. We consider the number of electrons \[
	N = V \int_0^{\infty} g(E) n_F\left( \beta\left( E - \mu \right)  \right) dE
\] \[
E(T) = V \int_0^{\infty} g(E) E n_F\left( \beta \left( E - \mu \right)  \right) dE
\] \[
C(T) = \frac{\partial E(T)}{\partial T}
.\] This integarl for $E(T)$ is very hard and usually solved numerically. To solve it analytically we make a few assumptions:
\begin{itemize}
	\item $\mu$ is independent from $T$. This only holds as long as we consider small Temperature changes
	\item $E(T) = E(T=0) + $ number of electrons that can be excided times amount of energy absorbed
\end{itemize}These assumptions yield \[
E(T) = E(T=0) + \frac{\gamma}{2}V g(E_F) K_B T * K_B T
\] \[
\implies c = \frac{\partial E}{\partial T} = \frac{\gamma}{2}V g(E_F) K_B^2 2 T
\] Using $g(E_F) = \frac{3}{2} \frac{n}{E_F}$ and $V = \frac{N}{n}$ \[
c = \gamma N \frac{3}{2} K_B \left( \frac{K_b T}{E_F} \right) 
.\] An accurate calculation yields $\gamma = \frac{\pi}{3}$. The final result of the heat capacity of the electrons is thus \[
c = \frac{\pi}{2} N K_B \left( \frac{K_B T}{E_F} \right) 
.\] The factor $\frac{K_B T}{E_F}$ is usually extremly small, as the Fermi-Energy is usually high. \\
For the total internal energy of the Fermi-Gas we gut \[
	U_{el} = \int_0^{\infty} E n_F\left( E\text{, }T \right) g(E) dE
.\] 

\chapter{The form of solids}
\section{LCAO - Linear Combination of Atomic Orbitals}
Is a quantum mechanical theory, also refered to as molecular orbital theory.\\
We consider two atoms, atom $A$ and atom $B$. We look that there's a electron orbiting the two atoms, in a molecule it will certainly interact with both atoms. For now we only consider a single electron.\\
We define the distance between the atoms $\vec{R}$ and the distance between the atoms and the electrons $\vec{R}_A$ and $\vec{R}_B$ respectively.\\
We assume that there is only one type of orbital. We will now try to write the hamiltonian of this system and deduce the Schroedinger Equation. \[
	\hat{H} = \hat{H}_{core} + \hat{H}_{valence}
.\] Where $\hat{H}_{core}$ only describes the nuclei and the core electrons and $\hat{H}_{valence}$ only describes the valence electrons.\\
We introduce a common assumption in Condensed Matter Physics called the Born-Oppenheimer approximation. It assumes:
\begin{itemize}
	\item nuclei in fixed positions
	\item kinetic energy of the nuclei $E_{kin,nuc} = 0$
\end{itemize}
These assumptions are valid, as the nuclei are much much heavier and move much slower than the electrons.\\
For the valence hamiltonian we get: \[
	H_{valence} = -\frac{\hbar^2}{2 m_e} \left( \frac{\partial^2}{\partial x^2} + \frac{\partial^2}{\partial y^2} + \frac{\partial^2}{\partial z^2} \right) - \frac{e^2}{4 \pi \epsilon_0} \left( \frac{1}{R_A} + \frac{1}{R_B} \right) 
.\] With the first term the kinetic energy of the electron and the second term it's coulomb energy. Since we assume that the nuclear kinetic energy is zero our hamiltanian only consists of this valence hamiltonian.\\
In LCAO we only search for solutions of the form \[
\ket{\psi} =  c_A \ket{\phi_A} +  c_B \ket{\phi_B}  
.\] With $\ket{\phi_{A\text{, }B}} $ the single atom orbitals. \\
To find the coefficients $c_A$ and $c_B$ we use a variational approach. \[
	\bra{\psi} H_{val} \ket{\psi }  = E \bra{\psi } \ket{\psi}  
.\] We want to minimize the Energy $E$. \[
E = \frac{\bra{ \psi } H_{val} \ket{\psi } }{\bra{\psi } \ket{\psi } } = \frac{\bra{c_A \phi_A + c_B \phi_B} H_{val} \ket{c_A \phi_A + c_B \phi_B} }{\bra{c_A \phi_A + c_B \phi_B} \ket{c_A \phi_A + c_B \phi_B} }
\] \[
\implies E = \frac{(c_A^2 \bra{\phi_A} H_v \ket{\phi_A} + c_B^2 \bra{\phi_B} H_v \ket{\phi_B} + 2c_Ac_B \bra{\phi_B} H_v \ket{\phi_A})} {c_A^2 \bra{\phi_A} \ket{\phi_B} + 2c_Ac_B \bra{\phi_B} \ket{\phi_A} +c_B^2 \bra{\phi_B} \ket{\phi_B}  }
.\]  
We introduce the binding integrals $H_{ij}$ as \[
	H_{ij} = \bra{\phi_i} H_v \ket{\phi_j}  = \int \phi_i^*\left( \vec{r} \right) \hat{H}_v \phi_j\left( \vec{r} \right) d\vec{r}
.\] For example $H_{A A}$ describes the energy of the energy of an electron around atom $A$ that still feels the precence of atom $B$.\\
We further introduce the overlap integrals \[
	S_{ij} = \bra{\phi_i} \ket{\phi_j} = \int \phi_i^*\left( \vec{r} \right) \phi_j\left( \vec{r} \right) d\vec{r}
.\] For all of these $0 \le S_{i j} \le 1 $. With $S_{ij} = 0$ meaning that the two orbitals do not overlap at all and $S_{ij} = 1$ meaning that the orbitals overlap perfectly.\\
These definitions help with our goal to minimize $E$.\[
E = \frac{\bra{\psi } H_v \ket{\psi } }{\bra{\psi } \ket{\psi } }
.\] To find the mimimum we set de derivative to $0$ \[
\frac{\partial E}{\partial c_A} = \frac{\partial E}{\partial c_B} = 0
\] \[
E = \frac{(c_A^2 \bra{\phi_A} H_v \ket{\phi_A} + c_B^2 \bra{\phi_B} H_v \ket{\phi_B} + 2c_Ac_B \bra{\phi_B} H_v \ket{\phi_A})}{c_A^2 \bra{\phi_A} \ket{\phi_B} + 2c_Ac_B \bra{\phi_B} \ket{\phi_A} +c_B^2 \bra{\phi_B} \ket{\phi_B}}
\]  \[
= \frac{c_A^2 H_{A A} + 2c_Ac_B + c_B^2 H_{BB}}{c_A^2 + 2 c_Ac_B + c_B^2}
\] \[
\implies \frac{\partial E}{\partial c_A} = 0 = \text{\ldots}
\] \[
\implies E = \frac{c_A H_{A A} + c_B H{AB}}{c_A + c_B S_{AB}}
\]If we also consider the deriviative with respect to $c_B$ we get: \[
c_A\left( H_{A A } - E \right) + c_B\left( H_{AB} - S_{AB}E \right) = c_A\left( H_{AB} - ES_{AB} \right) + c_B\left( H_{BB} - E \right) =0
.\] If we assume $H_{ii} = E_0$ (which holds as long as atom $A$ and $B$ are of the same type) we get two equations \[
c_A\left( H_{A A} - E \right) + c_B \left( H_{AB} - S_{AB}E \right) = 0 
\]\[
c_A\left( H_{AB} - S_{AB}E \right) + c_B \left( H_{BB} - E \right) = 0
\] \[
\implies \left( E_0 - E \right) ^2 - \left( H_{AB} - S_{AB}E \right) ^2 = 0
.\]   \[
\implies E_{\pm} = \frac{E_0 \pm H_{AB}}{1 \pm S_{AB}}
.\] Bonding thus introduces new energy eigenstates $E_+$ and $E_-$, one above and one below the original level $E_0$. We call the lower level $E_+$ the bonding energy and the higher level  $E_-$ the antibonding energy. (since $H_AB \ll 0$ we get $E_+$ as the lower level). We define  $V_1 = E_0 - E_+$ and $V_2 = E_0 - E_-$. In general we find  \[
\abs{V_1} < \abs{V_2}
.\] 
The antibonding level is thus always enough to 'counteract' the bonding level.\\
We can thus define the binding energy $E_B^{molecule}$. If only the bonding level is occupied we get \[
	E_B^{molecule} = 2 \abs{V_1} = 2\left( E_0 - E_+ \right) 
.\] With the factor of $2$ comming from two electrons occupying the level. \[
S_{AB} \ll 1 \implies E_+ = \frac{E_0 + H_{AB}}{1 + S_{AB}} \approx E_0 + H_{AB}
\] \[
\implies E_B \approx 2\left( E_0 - \left( E_0 + H_{AB} \right)  \right) = -2 H_{AB}
.\]  
We consider the splitting energy $E_- - E_+ = -2H_{AB}$. \\
Untill now we have not included the coulomb repulsion of the nuclei, for a correct approach we would have to include this.\\
We now want to determine $c_A$ and $c_B$. For this we now assume $S_{AB} \approx 0$. \[
	c_A\left( E_0-E \right) +c_BH_{AB} = 0
.\] We find:
\begin{itemize}
	\item For $E = E_+$ : $c_A = c_B = \frac{1}{\sqrt{2} } $ 
	\item For $E = E_-$ : $c_A = -c_B = \frac{1}{\sqrt{2} }$
\end{itemize} We therefore write \[
\text{Bonding Wavefunction: }\ket{\psi_+} = \frac{1}{\sqrt{2} } \left( \ket{\phi_A} + \ket{\phi_B}  \right) 
\] \[
\text{Antibonding Wavefunction: }\ket{\psi_-} = \frac{1}{\sqrt{2} } \left( \ket{\phi_A} - \ket{\phi_B}  \right) 
.\]  
We call this kind of bonding $\sigma$-bonding. A $\sigma$-bond is defined as any bond where only one orbital-lobe from each atom contributes (the types of lobes interacting does not matter, it could be S type orbital-lobes or P type orbital-lobes). If two lobes are contributing to the bond, we call it a $\pi$-bonding.

\section{Crystal Structures and Symmetries}
In Crystals we get Periodic Potentials \[
	V(\vec{r}) = V(\vec{r} + \vec{R})
.\] 
\chapter{Vibrations of a 1D-Atomic Chain}
If you assume stationary atoms, you cannot explain certain physical properties:
\begin{itemize}
	\item Thermal Expansion
	\item thermal conductivity and specific heat (can be modelled but not correctly)
\end{itemize}
We call a quantum of the atomic vibration a \emph{Phonon}. In classical mechanics this would be called a normal mode.\\
We have seen, that the interantomic potential has a asymmetric shape, with the attraction being less steep than the repulsion. As an approximation we assume that the potential is well approximated by a parabola, at least around the equilibrium posistion. \[
	V(x) = V\left( x_{eq} \right) + \frac{c}{2} \left( x -x_{eq} \right)^2 + \frac{c}{3!}O(x^3)
.\] In the harmonic approximation we now only consider the first two terms: \[
V_{Harm} = V\left( x_{Eq} \right) + \frac{2}{2} \left( x - x_{Eq} \right)^2
.\] At high temperatures the harmonic approximation fails.\\
In the asymmetrical potential we can already see an intuitive explanation for the thermal expansion: \[
\overline{x_{Eq}}\left( T \right) = \frac{x_{min} + x_{max}}{2} > x_{Eq}
.\] This effect however is not modelled in the harmonic approximation, which is symmetrical.
\section{Monoatomic Chain (Harmonic)}
We model a chain of identical Atoms (same mass, charge etc.) in a harmonic potential. This situation is analogous to a chain of mass points connected by springs. As long as we are in the harmonic approximation, we can imagine the atoms connected by springs.\\
We call the atom in 'the center' of the chain $n$, its' left neighbour $n-1$ and its' right neigbour $n+1$. We call the equilibrium distance between two of the atoms $x_{Eq} = a$ the lattice constant. We call the position of atom $i$ $x_i$. We thus know the equilibrium position of atom $i$; it is given by \[
x_i^0 = i*a
.\] We now consider vibrations (for example due to temperatures) \[
\delta x_i = x_i - x_i^0
.\] We can now apply Hooke's law: $\vec{F} = -c \Delta x$ \[
\implies \vec{F} = m \vec{a} = -c \Delta x
\] \[
\implies m \delta \ddot{x_n} = - c \delta x_n = - c\left( [\delta x_n - \delta x_{n+1}] + [\delta x_n - \delta x_{n-1}] \right) = c \left( \delta x_{n+1} + \delta x_{n-1} - 2 \delta x_n \right) 
.\] We only cosidered atoms moving alnog the chain, we only consider longitudinal waves for now. \\
As an ansatz for a solution we take: \[
	\delta x_i = A \exp{i \omega t - i k \dot{x_n}}
.\] With the frequency $\omega \ge  0$; note there's only one $\omega$, as in a normal mode all atoms vibrate with the same frequency. With the wavevector $k$ and $x_n = n*a$ as before.
To find $\omega$ we write \[
	m \delta \ddot{x_n} = A m \left( i \omega \right)^2 \exp{i\omega t - i k n a} = C A \exp{i\omega t} \left( \exp{- i k a\left( n+1 \right) } + \exp{-ixa\left( n-1 \right) }- 2 \exp{-ikan} \right) 
\] \[
= C \exp{-ikna} \left( 2 \cos{k a} - 2 \right) 
\] \[
\implies -m\omega^2 \exp{-ikna} = C \exp{-ikna} \left( 2 \cos{ka} - 2 \right) 
\] \[
\implies \omega^2 = \frac{4C}{m}\sin^2{\frac{ka}{2}}
.\] We thus find the frequency $\omega$ as: \[
\omega(k) = 2 \sqrt{\frac{C}{m}} * \abs{\sin{\frac{ka}{2}}}
.\] We call the relation between $\omega$ and the wavevector $k$ a dispersion relation. We have this found above the dispersion relation of a 1-D Monoatomic Chain.\\
We see that this function is periodic with $k \to k \pm \frac{2 \pi}{a}$.\\
In general we know that: If a system is periodic in real space ($x$, $y$, $z$) then it is also periodic in the recipcocal space ($k_x$, $k_y$, $k_z$).\\
This is a usefull fact that will come in handy many times.\\
We call one of the periodic zones in the repciprocal space a Brillouin zone (BZ). The first Brillouin zone reaches from $-\frac{\pi}{a}$ to $\frac{\pi}{a}$. It is usually sufficient to plot any function within the first BZ.\\
We thus find that $\delta x_n(k) = \delta x_n(k+\frac{2 \pi}{a}) $. \[
	\delta x_n(k) = A * \exp{i\omega t - i k na}
\] \[
\delta x_n(k \pm \frac{2\pi}{a}) = A \exp{i \omega t - i \left( k \pm \frac{2 \pi}{a} \right) n a} = A \exp{i\omega t - i kna} * \exp{-i 2 \pi n}
.\] \[
\implies n \in \mathbb{Z}
.\]  We say that $\vec{k}$ is defined up to any lattice vector. In our case the lattice vector is $\frac{2\pi}{a}$. We thus define the reciprecal lattice vector $G_m$ \[
G_m = \frac{2\pi}{a}*m \text{, } \forall m \in \mathbb{Z}
.\] We get \[
\exp{i \vec{Gm} \vec{x_m}} = 1
.\] We can thus turn the definition around and say that this exponential gives the definition of the reciprocal lattice. 
\subsection{}
We found the dispersion relation \[
	\omega = 2 \sqrt{\frac{C}{m}}  * abs{\sin{\frac{ka}{2}}}
.\] We now think about this relation
\begin{itemize}
	\item $k \to  0$ we find: $\implies \omega = 2 \sqrt{\frac{C}{m}} \frac{ka}{2} = \sqrt{\frac{C}{m}} *ka$ \\
		We thus find a linear dispersion relation $\omega \propto k$ with a constant called the speed of sound: $\omega = k * v_{sound}$. Any time we find a linear dispersion we call it a sound like dispersion. \\
\end{itemize}
We define certain velocities: 
\begin{itemize}
	\item Sound Velocity $V_s = a \sqrt{\frac{C}{m}} $ is the velocity of the wave at $k = 0$.
	\item Phase Velocity $v_{phase} = \frac{\omega}{k}$ speed at wich the maxima and minima travel 
	\item Group Velocity $v_{group} = \frac{d\omega}{dk}$ speed of the wave packet
\end{itemize}
For materials with linear dispersion we find $v_p = \frac{\alpha k}{k} = \alpha = \frac{d\left( \alpha k \right) }{k} = v_g$. Phase and group velocities ore equal only for linear dispersion. \\
For example we find in the case of the monoatomic chain, that the group velecity $v_g = 0$ for $k = \frac{\pi}{a}$. \\
How do we count the number of normal modes? \[
\text{\#modes} = \frac{\text{\#all possible }k}{\text{spacing between neighbouring }k} = \frac{\frac{2\pi}{a}}{\text{?}}
\] 
To find the spacing between the possible $k$, we use periodic boundary condition: $x_i = x_{i+N}$.\\
Meaning that we assume the monoatomic chain to be a closed loop. We get that: \[
	A \exp{i \omega t - iKna} = A \exp{i\omega t - iK\left( n+N \right) a)}
\]\[
\implies \exp{-iKNa} = 1
\]\[
\implies K = P\frac{2\pi}{Na}\text{ , } \forall P \in \mathbb{Z}
.\] We thus know the number of modes as: \[
\text{\#modes} = \frac{\frac{2\pi}{a}}{\frac{2\pi}{Na}} = N
.\] We find that the total number of modes is equal to the number of atoms, since we are considering only longitudinal waves in our 1D system this is also the number of degrees of freedom. While Debye had to introduce a cutoff frequency to get this result, we now found it generally.
\subsection{Types of Vibrations}
Up to now we only considered longitudinal waves in our 1D system. In addition to the $\delta x$ we already considered there are also $\delta y$ and $\delta z$ to consider. Since $\delta y$, $\delta z \bot \vec{K}$ these waves are Transverse modes. In general we find \[
	\omega\left( \text{Tronsverse mode} \right) < \omega\left( \text{longitudinal mode} \right) 
.\] 
\section{Diatomic linear chain}
We sitll assume a harmonic potential, but now we assume that we have two different types of atoms, repeating in a ABABABA manner. We thus get different spring constants $C_1$ and $C_2$ and different masses $m_1$ and $m_2$. 
The first step to solve such a problem, is to select a periodic unit cell.  We thus select a unit cell of length $a$ that includes one atom pair AB.\\
The next step is to identify a reference point, since the unit cell is no longer symmetrical the center of the unit cell is no longer the center of mass. Instead of describing the position of an atom like before, we now call the coordinate of that reference point $\delta x_n$. We thus get the position of the unit cell as $r_n = n*a$.\\
The third step is to describe the position of the atoms in relation to the reference point. We call the positions of the Atoms \[
	x_n^{eq} = an - \alpha a
\]\[
y_n^{eq} = an + \beta a
.\]  For simplicity we assume $m_1=m_2$ and $c_1 \neq c_2$, without loss of generality we assume $c_2 > c_1$.\\
We now solve the problem simmilar as before. We consider the force on one of the atoms \[
	F_1 = m \delta \ddot{x_n} = c_2 \left(\delta y_n - \delta x_n  \right) + c_1 \left( \delta y_{n-1} - \delta x_n \right)  
\] \[
	F_2 = m \delta \ddot{x_n} = c_2 \left(\delta x_n - \delta y_n  \right) + c_1 \left( \delta x_{n+1} - \delta y_n \right)  
.\] We choose the ansatz \[
\delta x_n = A_x \exp{i \omega t - i Kna}
\]\[
\delta y_n = A_y \exp{i \omega - iKna}
.\] We get two different amplitudes, but the same frequency. As the definition of a normal mode is per its' frequency. \\
As befor we get $\omega > 0$, $K$ positive or negative and the number of  $K$ values $= \frac{\text{range of }K}{\text{spacing of }k} = \frac{\frac{2\pi}{a}}{\frac{2\pi}{Na}} = N$.\\
We have to remember that $N$ here is the number of unit cells, not the number of atoms. \\
By inserting the ansatz into the equation of motion we get: \[
	-\omega^2 m A_x \exp{i\omega t - i Kna} = c_2 A_y \exp{i\omega t - i Kna} + c_1 Ay \exp{i\omega t - i Kna} - \left( c_1+c_2 \right) A_x \exp{i\omega t - iKa}
\] \[
\implies \omega^2 m \begin{bmatrix} A_x \\ A_y \end{bmatrix} = \begin{bmatrix} c_1+c_2 & -c_2-c_1\exp{ika}\\ -c_1 \exp{-ika}-c_2 &  c_1+c_2 \end{bmatrix} \begin{bmatrix} Ax \\ Ay \end{bmatrix} 
.\] We thus get an  Eigenvalue problem the solution yields: \[
m\omega^2 = c_1+c_2 \mp \sqrt{c_1^2 + c_2^2 + 2c_1c_2 \cos\left( ka \right) } 
\] \[
\omega_{\pm} = \sqrt{\frac{c_1+c_2}{m} \mp \frac{1}{m} \sqrt{c_1^2 + c_2^2 + 2c_1c_2\cos\left( ka \right) } } 
\]  For each $K$ we thus get two possible $\omega$. We therefore have two dispersion relations $\omega_+\left( K \right) $ and $\omega_-\left( K \right) $. We call these two dispertion relations \emph{phonon branches}. \\
In this case the two phonon branches have fomous names:
\begin{itemize}
	\item $\omega_-$ is called the \emph{acoustic branch}\\
		$\lim_{K \to 0} \omega_-(K) = \sqrt{\frac{c_1c_2 a^2}{2\left( c_1+c_2 \right) }} \abs{K}$\\
		We see that $\omega_-$ has a linear dispersion (acoustic dispersion) at small $K$.
	\item $\omega_+$ is called the \emph{optical branch}\\
		$\lim_{K \to 0} \omega{K} = \sqrt{\frac{2 \left( c_1+c_2 \right) }{m}} $\\
		The optical branch has a group velocity of $v_g = \frac{d\omega_+}{dK} = 0$.\\
		The reason that this branch is called the optical branch is, that we can measure it by using light as a pertubation.
\end{itemize}
We thus see that for $K \to 0$ we get two different values. We get \[
	\omega_-(K ->0)
\]\[
\implies \begin{bmatrix} 0 \\ 0 \end{bmatrix} = \frac{c_1 + c_2}{m} \begin{bmatrix} A_x - A_y \\ -A_x + A_y \end{bmatrix} 
\] \[
\implies A_x = A_y
.\] In acoustic branches tho atoms vibrate in phase.\\
For the optical branch we get:
\[
\text{\ldots} \implies A_x = -A_y
.\] 
In optical branches the atoms vibrate out of phase.\\
Because the energy requirement of vibrating out of phase is much higher we find: \[
	\omega\left( \text{optical branches} \right) > \omega\left( \text{acoustical branches} \right) 
.\] (We have demonstarted this only at $K = 0$ but it holds in general).\\
We will now also demonstarte it ot the BZ boundaries $K = \pm \frac{\pi}{a}$ : \[
	\omega_+\left( k = \frac{\pi}{a} \right) = \sqrt{\frac{2c_2}{m}} 
\]\[
\omega_-\left( k = \frac{\pi}{a} \right) = \sqrt{\frac{2c_1}{m}} 
.\]  Since we know $c_2 > c_1 \implies \omega_- < \omega_+$.\\
In summary
\begin{itemize}
	\item For the monoatomic Chain we got:\\
		\begin{itemize}
			\item 
		\end{itemize}
	\item For the diatomic chain we got ($2N$ atoms):
		\begin{itemize}
			\item 2N Branches
		\end{itemize}
	\item in general:\\
		If there are $M$ atoms in a unit cell we will get $M$ modes at each $K$.\\
		We always get $1$ acoustic mode and $M-1$ optical modes.\\
		In $d$ dimensions we get $d*M$ modes at each $\vec{K}$. We find $d$ acoustic modes and $d\left( M-1 \right) $ optical modes.
\end{itemize}

\section{Quantum Correspondence}
Discrete quantum vibrations of phonons with energy $\hbar \omega$. We utilize the Bose occupation factor again, as phonons are bosons \[
	n_B\left( \hbar \omega \beta \right) = \frac{1}{\exp\left( \hbar \omega \beta \right) - 1}
.\] We thus find the energy expectation of a single phonon as \[
<E_n> = \hbar \omega_k \left( n_B + \frac{1}{2} \right) 
.\] For the total enerrgy we have to sum over the first BZ \[
U_{tot} = \sum_{k=-\frac{\pi}{a}}^{\frac{\pi}{a}} \hbar \omega_k\left( n_B + \frac{1}{2} \right) 
.\] For example in the case of a mono-atomic chain we found: \[
\omega_k = 2 \sqrt{\frac{c}{m}} \abs{\sin\left( \frac{ka}{2} \right) }
.\] For many atoms $N \to \infty$ we get $\sum_{k} \to \frac{L}{2\pi} \int_{-\frac{\pi}{a}}^{\frac{\pi}{a}}dK$.\\
This is a more general expression for the total energy, as for example we found in the Einstein or Debye models:
\begin{itemize}
	\item Einstein: $\omega_k = \omega_{einstein}$ 
	\item Debye: $\omega_k = v_s * k$
\end{itemize} But now we can correctly describe $\omega_k$ without using these approximations. \\
As before we can introduce the density of states $g(\omega)$. \[
	\frac{L}{2\pi} \int dK = \int g(\omega) d\omega
\] \[
g(\omega) = 2 \frac{Na}{2\pi} \abs{\frac{dK}{d\omega}} \propto \frac{1}{\abs{\frac{d\omega}{dK}}}
\] For mono atomic chains we thus find \[
g(\omega) = \frac{1}{\cos(\frac{ka}{2})}
.\] 
\section{Crystal Momentum}
$K$ is fully equivalent to $K \pm G_m$, as defined before. \\
We define crystal momentum as \[
	\hbar \left( K \mod \frac{2\pi}{a} \right) 
.\] We thus get that the conservation of momentum is still valid, but is not absolute, instead it occures modulo $\frac{2\pi}{a}$. This basically means, that the momentum is always defined by the equivalent $K$ in the first BZ.\\
\chapter{Thight binding chain}
We consider electrons in periodic potentials. We assume equally spaced atoms, each with only one available orbital.\\
We define $\ket{n} $ as the orbital of the $e^-$ on the atom $n$. We also assume $\bra{n} \ket{m} = \delta_{mn}$. As before we have LCAO with $S_{AB} = \bra{\phi_A} \ket{\phi_B} = \delta_{mn} $, this is only an approximation, but holds in this toy model. We write the (Born-Oppenheimer) hamiltonian as \[
	\hat{H} = \frac{\vec{p}^2}{2m} + \sum_{j} V \left( \vec{r}- \vec{R}_j \right) = K + \sum_{j} V_j
.\] We make an Ansatz for a trial wavefunction as \[
\ket{\psi} = \sum_{n} \phi_n \ket{n} 
.\] To find the factors $\phi_n$ we solve the Schroedinger Equations: \[
\sum_{m} H_{nm} \phi_m = E \phi_n
.\] Proof: \[
E = \frac{\bra{\psi } H \ket{\psi } }{\bra{\psi } \ket{\psi } }
\] Missing\\
We can define the energy of one atom as \[
	E_m \ket{m} = H \ket{m} = \left( K + V_m \right) \ket{m} 
.\] 
In the case where we have many nuclei we get \[
H = K + V_m + \sum_{j \neq m} V_j	
.\]\[
\implies E \ket{m}  = E_m \ket{m} + \sum_{j \neq m} V_j \ket{m} 
.\] \[
\implies H_{nm} = \bra{n} H \ket{m} = E_{atomic} \bra{n} \ket{m} + \bra{n} \sum_{j \neq m} V_j \ket{m} 
.\] 
\begin{itemize}
	\item $n = m \implies \bra{n} \sum_{j} V_j \ket{m} = \bra{m} \sum_{j} V_j \ket{n} = V_0$
	\item $n \neq m \implies \bra{n} \sum_{j \neq n} V_j \ket{m} = -t$ "Hopping energy"\\
		if $\abs{n - m} > 1 \implies $ "Hopping" $\approx 0$, we assume that only direct neighbours interact with each other.
	\item $\abs{n-m} > 1 \implies \sum_{j \neq n} \bra{n} V_j\ket{m} = 0 $
\end{itemize}
\[
	\implies H_{nm} = E_{atomic} \delta_{nm} + \bra{n} \sum_{j} V_j \ket{m} = (E_a + V_0) \delta_{nm} + (-t) * \left( \delta_{n\text{,}m+1} + \delta_{n\text{,}m-1} \right) 
\] \[
\implies H_{nm} = E_0 \delta_{nm} - t \left( \delta_{n\text{,}m+1} + \delta_{n\text{,}m-1} \right) 
\]  We make the ansatz $\phi_n = \frac{\exp(-ikna)}{\sqrt{N} }$. \[
\sum_{m} H_{nm} \phi_m = E \phi_n
\] \[
\frac{E_0 \exp(-ikna)}{\sqrt{N} }= \frac{t}{\sqrt{N} } \left( \exp(-ik(n-1)a) + \exp(-ik(n+1)a) \right) = E \frac{1}{\sqrt{N} } \exp(-ikna)
\] \[
\implies E = E_0 - 2t \cos{(ka)}
.\]   
We call this relation between $E$ and $K$ the electric dispersion. This gives us an energy band, aka. the possible energies for the electrons. \\
We have found $\phi_n = \frac{\exp\left( -ikna \right) }{\sqrt{N} }$. The wavefunction of an electron is therefore delocalized over the whole cristal.\\
If we expand $E$ around $K \approx 0$ we get: \[
	E \approx E_0 - 2t\left( 1 - \frac{\left( ka \right) ^2}{2} \right) = \text{const.} + t k^2a^2
.\] Quadratic dependence!\\
For free electrons we know $E = C + \hbar \frac{K^2}{2m}$, at $K \approx 0$ we therefor get a simmilar behaivour as for free electrons. We find that \[
\frac{\hbar^2}{2m^*} = a^2 t
\] \[
E = \text{const.} + \frac{\hbar^2 K^2}{2m^*}
.\] With the 'effective mass' $m^*$ which depends on $t$. For now this effective mass is only a mathematical constant with a dimension of a mass, later we will see that it also has a physical meaning. The effective mass has no relation with the real mass of the electron.\\
Above we spoke of an energy band, but is this justified, the $K$ vectors are discrete, shouldn't we get discrete energy levels from this?\\
Tchnically we do, but there are many states in a relatively small interval of energy, we can therefore assume a continous energy band.
We now want to count the states \[
\text{\# of states} = 2 * 2 * \frac{dN}{dE}
\] $K$ can be $\pm$ and there are two electrons per level $\to 2 * 2$. Rewriting \[
\frac{dN}{dE} = \frac{dN}{dK} \frac{dK}{dE}
.\] We know that $\frac{dK}{dN} = \frac{2\pi}{L}$ and we also know the dispersion relation between $K$ and $E$.
\section{Monovalent Atoms}
Monovalent Atoms have only $1$ electron in the outer most shell. $N \text{atoms} \to N e^-$.\\
But the energy Band can host $2N$ electrons, it will thus only be half filled. The band will be filled from the bottom up, since there are free electron bands, there can be an exitation this results in the kristal being able to conduct electricity and heat really well.
\section{Divalent Atoms}
$N \text{atoms} \to 2N$ electrons. All bands are filled, diatomic crystals are insulators and their electrons don't contribute to the heat capacity.
\section{N orbitals in the unit Cell}
There are either more than one atoms per unit cells or each atom has more than one orbital. This is the most common situation.\\
This situation is analougous to the phonos in a diatomic chain. We also get two dispersion branches.\\
Example: 3 electrons in each unit cell. $N$ atoms $\to 2N$ possible energies in the first energy band but $3N$ electrons. We completely fill the lower band and then fill the remaining electrons into the higher band.\\
The filled lower band does, as above, not contribute to thermal or electrical conduction. However the higher band is not completely filled and thus exitations are possible, this higher band contributes to the thermal and electrical conductivity. The smallest distance between the two bands is called a 'band gap'.
\chapter{Crystaline Structures}
A crystal is an arrangement of material, which is periodic in space. This can mean a periodic arrangement of atoms or whole molecules.
\section{Important definitions}
\begin{itemize}
	\item A crystal is a PERIODIC arrangements of atoms
	\item A lattice is a set of points defined as integer sums of \emph{primitive lattice vectors}
\end{itemize}
A lattice has three main characteristics:
\begin{enumerate}
	\item A lattice is a set of points defined as integer sums of \emph{primitive lattice vectors}
	\item A lattice is a set of vectors such that addition of two valid lattice vectors gives a third valid vector
	\item A lattice looks the same from every lattice point.
\end{enumerate}
Any lattice describes a crystal, but not every crystal can be described by a lattice.\\
Any periodic structure can be transformed in a lattice by carefully choosing a unit cell. If we have a periodic structure we can choose a unit cell as a \emph{basis} such that these cells form a lattice.\\
We can thus describe each crystal by choosing a suitable basis and it's corresponding lattice. The choice of the unit cell is not unique. We can therefore choose unitcells such that it's mathematically convinient.\\
A famous example of a unit cell are the so called Wigner-Seitz unit cell. It is defined as the region of space around a given lattice point, that is closer to this lattice point than to any other.\\
To fully describe a crystal we have to specify the basis and the positions of the atoms within these unit cells.
\section{Symmetry Operations}
Symmetry operations can be used to classify lattices.
\begin{itemize}
	\item Translational Symmetry:\\
		There always exists a vector $\vec{R}$ such that a translation by $\vec{R}$ leaves the system unchanged. ALL CRYSTALS HAVE TRANSLATIONAL SYMMETRY
	\item Rotational Symmetry:\\
		We can rotate the system by an angle $\sigma$ such that the system remains unchanged. Not all crystals have rotational symmetry.
	\item Reflection\\
		There can be one or many mirror planes such that a reflection across these planes leaves the system unchanged. Not all crystals have a Symmetry in reflextion.
	\item Inversion\\
		$\left( x, y, z \right) \to \left( -x, -y, -z \right) $. Not all crystals have a Inversion symmetry.
\end{itemize}
Some parts missing here\\
\subsection{Summary of the proporties of the recprocal lattice}
\begin{itemize}
	\item For every direct lattice $\exists$ a recprocal lattice
	\item The recprocal of a reciprocal lattice is the original direct lattice\\
		if we have a set of reciprocal lattices $\{\vec{G}\}$ and  it's reciprocal is $\{\vec{M}\}$\\
		$\implies e^{i \vec{G} \cdot \vec{M}} = 1$ i.e. $\{\vec{M}\} = \{\vec{R}\}$
		\item $\vec{R} \cdot \vec{G} = 2 \pi m$ with $m \in \mathbb{Z}$
	\item  $\vec{G}\left( h,k,l \right) = h \vec{b_1} + k \vec{b_2} + l \vec{b_3}$, where $h,k,l$ are the miller indecies. $\vec{G} \perp \left( k \text{ } k \text{ } l \right) $ lattice plane.
\item The separation between lattice planes of the direct lattice ($h$ $k$ $l$) \\
		$d(h,k,l) = \frac{2\pi}{\abs{\vec{G}(h,k,l)}} = \frac{a}{\sqrt{h^2 + k^2 + l^2} }$
\end{itemize}
\section{Brillouin Zone}
We want to study waves in crystals (eg. electrons or phonons). \\
We define the Brillouin Zone (BZ) as the unit cell of the reciprocal lattice. \\
We call the N$^{\text{th}}$ BZ: points in $\vec{k}$ space where $\vec{k} = 0$ is the N$^{\text{th}}$ closest reciprocal lattice point are the N$^{\text{th}}$ BZ. This corresponds to the Wigner Seitz unit cell of the reciprocal lattice.
The number of $\vec{k}$ states in a BZ is equal to the number of unitacells in the system. \\
We consider some examples in 3d:\\
\begin{itemize}
	\item Lattice		| Rep. Lattice 	| First BZ
	\item Simple cubic 	| Simple cubic 	| Cube
	\item BCC		| FCC		| WS cell for FCC
	\item FCC		| BCC		| WS cell for BCC
\end{itemize}
\chapter{Reciprocal Space}
Missing TODO
\chapter{Scattering Experiments}
By sending a known wave with $\vec{k}$ into a sample we usually get a scattered part $\vec{k'}$ and an unscattered part $\vec{k}$. By studying the scattered wave $\vec{k'}$ we can infere the structure.\\
The wave should be comparable in size to the structure you want to investigate.  In CoMa we want to invesitgate crystal structures of solids, we thus need waves with a wavelength on the order of a few Angstroms. In particular we consider X-Rays and Neutrons. (In theory electrons are also feasable, but physically much more complex - in this lecture we only consider X-Rays and Neutrons).\\
The atoms in a crystal are producing a periodic potential. Our wave is interacting  with this potential $V(\vec{R})$ that is scattering the wave. $\implies$ we acctually probe this periodic potential.\\
\section{Fermi's Golden Rule}
We look ath the Scattering Rate $\Gamma$: \[
	\Gamma(k, k') = \frac{2\pi}{\hbar} \abs{\bra{\vec{k'}} V \ket{\vec{k}} }^2 \delta\left( E_{k'} - E_k \right)  
.\] 
We assume ELASTIC Scattering; this means we assume $E =E'$ and $\abs{\vec{k}} = \abs{\vec{k'}}$ \\
This is a reasonable assumtion as the majority of a scattered signal results from elastic scattering and only a negligable part of the signal results from inelastic scattering.\\
We now investigate the matrix element  \[
	\bra{k'} V \ket{k} = \int d\vec{r} e^{-i \vec{k'} \cdot \vec{r}} V(\vec{r}) e^{i \vec{k}\cdot\vec{r}} = \int d\vec{r} e_6{-i\left( \vec{k'} - \vec{k} \right) \cdot \vec{r}} V(\vec{r})
\] \[
= FT[V(\vec{r})]
.\]  
If we consider a periodic scattering potential we find \[
	FT[V(\vec{r})] = \frac{\left( 2\pi \right) ^3}{V_{unit cell}} \sum_{\vec{G}} \delta^3\left( \vec{k} - \vec{k'} - \vec{G} \right) S\left( \vec{G} \right) 	
.\] With the structure factor $S(\vec{G})$ given as \[
S(\vec{G}) =  \int_{unit cell} d^3\vec{r} e^{i \vec{G} \cdot \vec{r}} V(\vec{r})
.\] ANy periodiic potential has a FT with non-zero values only at the positions of the RECPROCAL LATTICE VECTORS and its values are weighted by the structure factor. We thus find:
\begin{enumerate}
	\item Scattering is non-zero onlf if $\vec{k} - \vec{k'} = \vec{G}$ \\
		this realtion which expresses the conservation of crystal momentum is called the Laue condition.
	\item Intensity of Scattering is proportional to $\abs{S(\vec{G})}^2$
\end{enumerate}
\section{Equivalence of Laue and Bragg Conditions}
The Laue condition is equivalent to imposing constructive interference between waves scattered on different lattice planes. \\
We assume a wave incident on a lattice plane with an angle of $\theta$. Note: the wave is thus deflected by $2\theta$.\\
A wave reflected on the second lattice plane has to travel an additional distance equal to $2 d \sin\left( \theta \right) $. To get constructive interference we need \[
	2 d \sin\left( \theta \right) = n \lambda
.\] 
We know that our $\vec{G}$ is perpendicular on the lattice plane. Since we only consider elastic scattering we have $\abs{k} = \abs{k'}$. We define $\hat{k}$, $\hat{k'}$, $\hat{G}$ as the unit vectors in the directons of the corresponding vectors. We find \[
	\hat{k'} \cdot \hat{G} = -\sin\left( \theta \right) 
\] \[
\hat{k} \cdot \hat{G} = \sin\left( \theta \right) 
.\] We rewrite the Laune condition \[
\frac{2\pi}{\lambda} \left( \hat{k} -  \hat{k'} \right) = \vec{G}
\] \[
\frac{2\pi}{\lambda} \left( \hat{G}\cdot \hat{k} - \hat{G}\cdot \hat{k'} \right) = \hat{G} \cdot \vec{G}
\]\[
\frac{2\pi}{\lambda} \left( \sin(\theta) - \left( -\sin(\theta) \right)  \right) = \abs{\vec{G}}
.\]  \[
\frac{2p}{\abs{\vec{G}}} 2 \sin(\theta) = \lambda
\] \[
2d\sin(\theta) = n*d \text{  with } n \in \mathbb{Z} 
.\]  We have now recavered the Bragg condition from the Laue condition. We have thus found that the conservation of momontum corresponds to constructive interference.\\
\section{Intensity of Scattering}
\[
	I \propto \abs{S\left( \vec{G} = \vec{k} - \vec{k'} \right) }^2
\] With $S = FT[V(\vec{r})]$. \\
\subsection{Neutron Scattering}
Neutrons interact mostly via short range nuclear forces. They only 'see' a short range potential of only the nucleus. \[
	V(\vec{r}) \propto \sum_{\text{atoms }\alpha} b_{\alpha} \delta^3(\vec{r} - \vec{r}_{\alpha})
\] With the scattering length $b_{\alpha}$, which can be both positive or negative. For positive $b_{\alpha}$ the nuclei and neutrons experience repulsive interaction, for negative $b_{\alpha}$ an attcactive interaction.\\
We'll now investigate the form of the structure factor $S(\vec{G})$ : \[
	S(\vec{G}) = \int_{\text{unit cell}} dr^3 e^{i \vec{G}\cdot\vec{r}} V(\vec{r}) = \int_{\text{unit cell}} e^{i \vec{G} \cdot \vec{r}} \sum_{\alpha} b_{\alpha} \delta^3\left( \vec{r} - \vec{r}_{\alpha} \right) 
\] \[
\implies S(\vec{G}) = \sum_{\text{atoms in unit cell}} b_{\alpha} e^{i \vec{G} \cdot \vec{r}_{\alpha}}
\]
\subsection{X-Rays}
As electron magnetic waves the X-Rays interact mostly with the electrons, which are delocalized. Our potential is thus proportional to the electron density. \[
	V(\vec{r}) \propto e^- \text{ density}
\] \[
V(\vec{r}) \propto \sum_{\alpha} Z_{\alpha} g\left( \vec{r} - \vec{r}_{\alpha} \right) 
\] With $Z_{\alpha}$ the atomic number of the atom in question, and the SHAPE FUNCTION $g(\vec{r} - \vec{r}_{\alpha}$ (behaves like a 'fat' delta function).\\
For this situation we find the structure factor as: \[
	S(\vec{G}) = \sum_{\alpha} \int_{\text{unit cell}} d^3r e^{i \vec{G} \cdot \vec{r}} Z_{\alpha} g_{\alpha}\left( \vec{r} - \vec{r}_{\alpha} \right) 
\] \[
= \sum_{\alpha} e^{i \vec{G} \cdot \vec{r}_{\alpha}} f_{\alpha}\left( \vec{G} \right) 
.\] With the atomic form factor $f_{\alpha}\left( \vec{G} \right) $ it is given as the FT of the shape function: \[
f_{\alpha}\left( \vec{G} \right)  = \int_{\text{all space}} d^3r e^{i \vec{G} \cdot \vec{r}} Z_{\alpha} g_{\alpha}(\vec{r})
\] Note: for the atomic form factor we are integrating over all space, not just the unit cell. This is neccesary because $g_{\alpha}(\vec{r})$ have long, non-zero, tails that 'bleed into' all unit cells. \\
In general we can say: \[
	S\left( \vec{G} \right) = \sum_{\text{atoms in unit cell }\alpha} e^{i \vec{G} \cdot \vec{r}_{\alpha}} \begin{cases}
			f_{\alpha}( \vec{G}) \\
			b_{\alpha}
	\end{cases}
\] We re-write the structure factor using the Miller indecies: \[
S\left( \vec{G} \right) = \sum_{\alpha} e^{2\pi i \left( h u_a + k v_a + l w_a  \right) } f_{\alpha}(\vec{G})
\] with ($h$, $k$, $l$ ) the Miller indicies and [$u_{\alpha}$, $v_{\alpha}$, $w_{\alpha}$ ] the position of the atom $\alpha$ in the unit cell.  
\section{Examples}
\subsection{Caesium Chloride}
CsCl is has a simple cubic lattice with basis [$0, 0, 0$ ] for the Cs, and [$\frac{1}{2}, \frac{1}{2}, \frac{1}{2}$ ] for the Cl.\\
What is the structure factor of CsCl? \[
			S\left( h, k, l \right) = f_{\text{Cs}}+ f_{\text{Cl}} e^{2\pi i \left( \frac{h}{2} + \frac{k}{2} + \frac{l}{2}  \right) }
	\] \[
	= f_{\text{Cs}} + f_{\text{Cl}} \left( -1 \right) ^{h+k+l} = \begin{cases}
		f_{\text{Cs}} + f_{\text{Cl}} , & \text{ for } h + k + l  \text{ even}\\
		f_{\text{Cs}} - f_{\text{Cl}} , & \text{ for } h + k + l \text{ odd}
	\end{cases}
	\]  
\subsection{Caesium}
Same lattice and basis as for CsCl, but both atoms are equal. (In principle this is a BCC, but it can also be described as a simple cubic with two basis) \[
	S_{h,k,l} = f_{\text{Cs}} + f_{\text{Cs}} \left( -1 \right) ^{h+k+l} = \begin{cases}
		0 , & \text{ for } h+k+l \text{ odd}\\
		2 f_{\text{Cs}} , & \text{ for } h+k+l \text{ even}
	\end{cases}
\] This result is not only true for Caesium, but for \emph{all} BCC lattices. This behaviour is called Selection Rule or Systematic Absence. 
\subsection{FCC Lattice}
FCC, like BCC, can be described as a simple cubic and a basis: $[0,0,0], [\frac{1}{2}, \frac{1}{2}, 0], [\frac{1}{2}, 0, \frac{1}{2}], [0, \frac{1}{2}, \frac{1}{2}]$. \[
	S = \sum_{\alpha = 0}^{4} e^{2\pi i (h,k,l) \cdot (u,v,w)_{\alpha}} = 1 + \left( -1 \right) ^{(h+k)} + \left( -1 \right) ^{(h+l)} + \left( -1 \right) ^{(k+l)}
\] \[
\implies S_{\text{FCC}} = 0, \text{ unless } h,k,l \text{ are all odd or all even}
.\]
\subsection{TiC}
FCC with basis: Ti $[0,0,0]$, C $[u,v,w]$. \[
	\abs{S_{\text{basis}}}^2 = \abs{b_{\text{Ti}} + b_{\text{C}} e^{2 \pi i \left( h, k, l \right) \cdot \left( u,v,w \right) }}^2
\] In an FCC crystial we only have two options for a second atom \[
[u,v,w] = \begin{cases}
	[\frac{1}{4}, \frac{1}{4}, \frac{1}{4}] & \text{as in }\\
	[\frac{1}{2}, \frac{1}{2},\frac{1}{2}] & \text{as in NaCl}
\end{cases}
\] We can simply try to insert both options and see which one matches the data, thus determining the basis of the inserted Atom.
\section{Independence of Selection Rules and Basis}
Selection Rules are independent of the Basis: \[
	S = S_{\text{lattice}} \cdot S_{\text{basis}}
	\] If $S_{\text{lattice}}$ goes to $0$ so does $S$. \[
S = \sum_{\alpha} f_{\alpha} e^{i \vec{G} \cdot \vec{r}_{\alpha}}
\] We now write $\vec{r}_{\alpha} = \vec{R}_{\alpha} + \vec{x}_{\alpha}$ the sum of the position of the lattice point and the basis. \[
S = \sum_{R \text{ in lattice}} \sum_{x \text{ in basis}} f_{\vec{x}} e^{i\vec{G} \cdot \left( \vec{R} + \vec{x} \right) } = \sum_{R \text{in lattice}} e^{i \vec{G}\cdot\vec{R}} \cdot \sum_{x \text{ in basis}} e^{i \vec{G}\cdot\vec{x}}
\]   \[
\implies S = S_{\text{lattice}} \cdot S_{\text{Basis}}
\] 
\section{How to realize X-RAY \& Neutron Scattering Experiments}
\begin{itemize}
	\item X-Rays from an X-rays tube\\
		High energy electrons are used to kick out core electrons from the material in the target. Electrons from the higher orbitals are then 'filling' the resulting holes in the core orbitals - as they do that, there is X-ray emission from this electronic emission. Since the energies of these transitions are extremly sharp (very well defined value) we get a very 'pure' wavelength X-ray source - ideal for scattering experiments.\\
		Unfortunatelly the amount of photons that can be produced with this technique is relatively limited.
	\item Synchrotron X-ray Sources\\
		Are $~10^10$ times more luminous than an X-ray tube. But requires huge equipment (there's one at PSI). In a synchrotron electrons are accelerated in a circular loop to big energies (GeV) and are then 'undulated' in undulators resulting in an oszilating motion, the electron oscilation in turn results in X-Ray emission. Unfortunatelly the resulting X-rays are not as well defined as in the method above, but one can filter for the wanted wavelength(s).
	\item Neutron Sources\\
		We need neutrons with wavelengths on the order of about $1$ Angstrom. We therefore know the needed momentum $p = \frac{1\pi \hbar}{\lambda} \implies E = \frac{p^2}{2m} \approx 80 meV$ which corresponds to about $800$ K.\\
		The problem is that common neutron sources (Nuclear reactors, or so called spalletion) emmit Neutrons with a much higher energy. We therefore have to cool down the neutrons using so called moderators. Moderators are materials in which the neutrons, when moving through them, loose velocity. To make the neutrons monochromatic we can either let them diffract with known crystals or use the Time of Flight (ToF) method. ToF works by letting the Neutrons fly through a known cavity with a shutter, allowing us to filter for a specific speed and thus a specific wavelength.
\end{itemize}
\chapter{Electrons in a periodic potential}
Is the fact that an axcitation at $\vec{k} + \vec{G}$ is the same as at $\vec{k}$ a general property or was it a result from the simplified tight binding model?
\section{Bloch Theorem}
An electron in a periodic potential $V(\vec{r}) = V(\vec{r} + \vec{R})$ has eigenstates of the form: \[
	\psi_k^{\alpha}(\vec{r}) = e^{i \vec{k}\cdot \vec{r}} \mu_R^{\alpha}(\vec{r})
\] With $\mu_k$ a periodic function with the same periodicity as the potential. These are modified plane waves, where $\vec{k}$ can be chosen to be in the first BZ. $\alpha$ is called the bound index, the eigenenergies are $E^{\alpha}(\vec{k})$.\\
Proof:\\
Consider the hamiltonian of our system: \[
H = H_0 + V
\] $H_0 = \frac{\vec{p}^2}{2m}$ the hamiltanian of the free electron and $V$ our periodic potential. We know that if $V = 0$ : \[
H_0\ket{\vec{k}} = E_k^0 \ket{\vec{k}} \text{  ,  } E_k^0= \frac{\hbar^2 \vec{k}^2}{2m}
.\] If $V \neq 0$ the electrons scatter from $\vec{k}$ to $\vec{k'}$ via a matrix element $\bra{k'} V \ket{\vec{k}} $. We know from before \[
\bra{\vec{k}'} V \ket{\vec{k}} = FT[V(\vec{r})]_{\vec{k} - \vec{k'}} =  \begin{cases}
	0 \text{ if } \vec{k} - \vec{k'} \neq \vec{G} \\
	V_{\vec{G}} \text{ if } \vec{k} - \vec{k'} = \vec{G}
\end{cases}
.\]  $\psi_k$ must have the form: \[
\psi_k = \sum_{\vec{G}} A_{\vec{G}+\vec{k}} e^{i\left( \vec{G} + \vec{k} \right) \cdot \vec{r}} = e^{i\vec{k}\cdot \vec{r}} \sum_{\vec{G}} A_{\vec{G} + \vec{k}} e^{i\vec{G}\cdot\vec{k}}
\]\[
\mu(\vec{r}) = \sum_{\vec{G}} A_{\vec{G} + \vec{k}} e^{i\vec{G}\cdot\vec{r}}
.\] We find the eigenstates $\psi_k$ as \[
\psi_{\vec{k} + \vec{G'}} = \sum_{\vec{G}} A_{\vec{G} + \vec{k} + \vec{G'}} e^{i\vec{G}\cdot \vec{r}} 
.\]  We can define $\vec{\hat{G}} = \vec{G} + \vec{G'}$ \[
= \sum_{\vec{\hat{G}}} A_{\vec{\hat{G}} + \vec{k}} e^{i \vec{\hat{G}} \cdot \vec{r}}
.\] Consequenses: 
\begin{itemize}
	\item All exxictations can be described within the first BZ
	\item A periodic potential does not scatter the crystal momentum
\end{itemize}
\section{Nearly Free Electron Mode}
We want to solve the SEq with a periodic potential $V(\vec{r}) = V(\vec{r} + \vec{R})$.
Approaches:
\begin{enumerate}
	\item Thight binding models: Atomic orbitals + weak hopping
	\item Nearly Free Electrons: plane waves + 'weak' periodic potential
\end{enumerate}
\[
H_0 \ket{\vec{k}} = E_k^0 \ket{\vec{k}} 
.\] How can we add a 'weak' potential? We assume the potential is a perturbation -> Pertubation theory.\\
First order pertubation theory: \[
E_k \approx E_k^0 + \bra{k} V \ket{k} = E_k^0 + V_0 
\] If we also consider the second order perturbation term we find: \[
E_k \approx E_K^0 + V_0 + \sum_{\vec{k'} \neq \vec{k}} \frac{\abs{\bra{k'} V \ket{k} }^2}{E_k^0 - E_{k'}^0}
\] \[
\sum_{k' \neq k} \frac{\abs{\bra{k'} V \ket{k} }^2}{E_k^0 - E_{k'}^0} = \sum_{\vec{G}} \frac{\abs{V_G}^2}{E_k^0 - E_{\vec{k}+\vec{G}}^0}
\] Problem: We get a divergence at $E_k = E_{k + G}$, this specifically happens at the BZ Boundaries (since at the BZ boundary $\abs{\vec{k}} = \abs{\vec{k} + \vec{G}} \implies E_k^0 = E_{k+G}^0$).
How do we treat the boundaries of the BZ? The answer is
\subsection{Degenerate Perturbation Theory}
The problematic points are the BZ boundaries and their immediate proximity ($\vec{k}$ and $\vec{k} + \vec{G}$). We specifically search for solutions around these problematic states.\\
We assume we are near the BZ boundary and look for an eigenstate of the form: \[
	\text{Trial wave function:  }\ket{\psi} = \psi_k \ket{\vec{k}} + \psi_{k+G} \ket{\vec{k} + \vec{G}}  
\] We now diagonalize the effective hamiltonian: \[
\sum_{m} H_\text{m,n} \phi_m = E \phi_n
\] We have to find the best linear combination of the "problematic" states to find the lowest energy state within the considered space. \[
\bra{\vec{k}} H \ket{\vec{k}} = \bra{\vec{k}} H_0\ket{\vec{k}} + \bra{\vec{k}} V \ket{\vec{k}} = E_k^0 + V_0
\]\[
\bra{\vec{k} + \vec{G}} H \ket{\vec{k} + \vec{G}} = E_{k+G}^0 + V_0
\]\[
\bra{\vec{k} + \vec{G}} H \ket{\vec{k}} = \bra{\vec{k} + \vec{G}} H_0 \ket{\vec{k}} + \bra{\vec{k} + \vec{G}} V \ket{\vec{k}} = E_k^0 \bra{\vec{k} + \vec{G}}\ket{\vec{k}} + V_{\vec{G}} = V_{\vec{G}} 
\]\[
\bra{\vec{k}} H \ket{\vec{k} + \vec{G}} = V_{-\vec{G}} = V_{\vec{G}}^*
.\] since $\ket{\vec{k}} $ and $\ket{\vec{k} + \vec{G}} $ are orthogonal. And with $V_{\vec{G}}$ the Fourier Transform of the potential. \[
\implies H = \begin{bmatrix} E_k^0 + V_0 & V_G^* \\ V_G & E_{k+G}^0 + V_0 \end{bmatrix} 
\] Assume $\vec{k}$ and $\vec{k} + \vec{G}$ are of the BZ boundaries: \[
\implies E_k^0 = E_{k+G}^0
\]\[
\implies E = E_k^0 + V_0 \pm \abs{V_{\vec{G}}}
\] We note that a periodic potential therefore affects the free electron wavefunction mainly at the BZ boundaries. A periodic potential opents up a gap in the dispersion of size $2 \abs{V_{\vec{G}}}$ at the BZ boundaries.\\
\section{Origin of the Energy Gaps}
Suppose in 1D to have a periodic potential of the form: \[
	V(x) = 2 \hat{V} \cos\left( \frac{2\pi}{a} x \right) 
\] This potential has the interesting characteristic of having only two fourier modes: \[
V_{\frac{2\pi}{a}} = V_{-\frac{2\pi}{a}} = \hat{V} \text{ and all the other } V_{\vec{G}} = 0
\] This makes the treatment of this potential mathematically simple, but the results we find are general for periodic potentitals.\\
The BZ boundaries in this case are: $\ket{k = -\frac{\pi}{a}} $ and $\ket{k = \frac{\pi}{a}} $\[
	\bra{x} \ket{k}  \to e^{\pm i\frac{\pi}{a}x}
\] We can diagonalize the hamiltonian to get two eigenfunctions: \[
\psi_\pm = e^{i\frac{\pi}{a}a} \pm e^{-i \frac{\pi}{a}x}
\] With the eigen energies \[
E_\pm = E_{\frac{\pi}{a}}^0 \pm \hat{V}
\] If we look at the probability density we find: \[
\abs{\psi_+}^2 \propto \cos^2\left( \frac{\pi}{a} x \right) \text{ , } \abs{\psi_-}^2 \propto \sin^2\left( \frac{\pi}{a}x \right)  
.\]   
The probability density $\abs{\psi_+}^2$ has it's maxima at the same positions as the potential, while the probability density $\abs{\psi_-}^2$ has it's maxima at the positions where the potential has it's minima. Therefore $\psi_+$ "sees" the potential very strongly and it's energy gets shifted up, while $\psi_-$ only "sees" the places where the potential is negative and therefore it's energy is shifted down.\\
\chapter{Band Theory}
From the bloch theorem we know that the eigenstates of an electron in a periodic potential take the form of a modified plane wave $\psi(\vec{r}) = e^{i\vec{k}\vec{r}} \mu_R(\vec{r})$. Using perturbation theory (and degenerate perturbation theory) we found that there exist gaps in the energy dispersion at the BZ boundaries. These gaps are proportional to the periodic potential.\\
We know so far from differet chapers:
\begin{enumerate}
	\item Filled band + Energy Gap ($\ge 4 \text{eV}$ ) $\to $ insulator
	\item Highest filled band: Valence band
	\item lowest empty band: conduction band
	\item Insulators for energy gaps $\ge 4$ eV
	\item Semiconductors are insulators with small energy gaps ( $\ll 4$ eV )
	\item We can count the states to know if the band is filled.\\
		$N$ unit cells $\to $ $N$ $k$-states, in each $k$-state we can put $2$ electrons (opposite spin) $\implies 2N$ electorns will fill a band. Any even number of electrons per unit cell can fill an integer number of bands.
	\item Metals have partially filled bands $\to$ usually (but not generally) odd numbers of electrons per unit cells is a metal.
\end{enumerate}
We call the highest filled band the \emph{valence band}, while the lowest empty band is called \emph{conduction band}. Depending on the energy gap between the valence and the conduction band we can classify materials as insulators, semiconductors and conductors in the way outlined above.\\
For monovalent atoms, each primitive unitcell only contributes one electron. See the slides for the bulk of content of this chapter.
\chapter{Semiconductors}
Within the previous chapter we saw that we have different energy bands. We called the highest filled band, the valence band and the lowest (partially) empty band the conductance band. In semiconductors we can exite an electron from the valence band to the conductance band, it leaves behind a \emph{hole}.\\
A \emph{hole} is an absence of an electron in an otherwise filled VB, it corresponds to an "empty orbital". A hole and an electron can recombine to give us a photon. \\
One can obtain an electorn + hole in a system by providing some additional energy. Another way of having holes in a system (without external excitations) is having partially overlapping bands. Electons and holes can move about within the respective bands.\\
We define \[
n = \text{ density of electrons in CB}
\] \[
p = \text{ density of electrons in VB}
\]  
In intrinsic (aka. pure) materials we always get: $n = p$ (Eg. pure silicon crystal)\\
In the precence of impurities: $n \neq p$ (Eg. dotted Silicon crystal)\\
Pure Si has a completely filled VB. For simplicity we consider a 2d-square lattice of Si-Atoms with one added Phosphor atom. We can think of the P atom as a Si atom with an additional electron, that has to occupy the conduction band.\\
If we instead replace one of the Si-Atoms with a Boron atom. We can think of this B-atom as a Si-Atom with one electron missing - this thus provides a hole in the VB. \\
We call these foreign atoms in the crystal \emph{Dopants}. Dopants are introduced in a pure substance to change it's properties. 
We call dopants that provide extra electrons n-dopants or donor impurity, while we call dopants that provide holes p-dopant or acceptor impurity.\\
\section{Electrons \& Holes in the Bands}
How do electrons in the CB and holes in the VB move?\\
We consider the dispersion of the CB around a minimum at $k_\text{min}$ and aproximate by tayloring. \[
	E = E_0 + \frac{1}{2} \frac{\partial^2 E}{\partial k^2}\left( k - k_\text{min} \right)^2 + \ldots
.\] We can define the electron effective mass $m_e^*$ as \[
\frac{1}{m_e^*} = \frac{1}{\hbar^2} \frac{\partial^2 E}{\partial k}
.\] such that the energy is given by \[
E = E_0 + \frac{\hbar^2 \left( k- k_\text{min} \right)^2}{2m_e^*}
.\] 
We can also define a group velocity \[
V_\text{group} = \frac{\partial \omega}{\partial k}
\] with $E = \hbar \omega \implies \omega = \frac{E}{\hbar}$ we find \[
V_\text{group} = \frac{1}{\hbar} \frac{\partial E}{\partial k} = \frac{\hbar \left( k - k_\text{min} \right) }{m_e^*}
.\] Note: 
\begin{enumerate}
	\item Effective mass can be anisotropic, meaning they can be different depending on the direction of the crystaline direction.
	\item There might be specific directions in which there are more than one minima in the dispersion. In this case we speak valleys at $k_i$.
	\item Since the effective mass is proportional to the curvature of the dispersion it can assume positive or negative values.
\end{enumerate}
\subsection{Mass of a Hole}
We consider a hole on top of the VB ("sitting at a maximum of the dispersion"), the curvature and thus the effective mass will be $< 0$. We define the mass of the hole, such that \[
\frac{\hbar^2}{m_h^*} = - \frac{\partial^2 E}{\partial k^2}
\] the mass of the hole is positive.\\
Note that the definition of the mass of a hole is exactly negative the effective mass of the electron.\[
m_h^* = - m_e^*
.\] 
Using this definition we can also define the energy of a hole \[
E_h = E_0 + \frac{\hbar^2}{2 m_h^*}k^2
.\] Moving a hole away from a maximum of the VB will increase the energy of the system.
\subsubsection{Momentum of a Hole}
We know that completely filled bands are inert $\implies$ they have no crystal momentum. If we now picture a band with a hole at a position and another band with an electron at the same position and 'add' them together we get an inert band. We therefore reason \[
\hbar k_h + \hbar k_e = \hbar k_\text{inert} = 0
\] \[
\implies \hbar k_h = -\hbar k_e
.\]  
\subsubsection{Velocity of a Hole}
For the electrons we have \[
E_e = E_0 - \frac{\hbar^2 k_e^2}{2m_h^*}
\] \[
v_g^e = \frac{1}{\hbar } \frac{\partial E_e}{\partial k_e} = - \frac{\hbar k_e}{m_h^*} = \frac{\hbar k_e}{m_e^*}
.\] The group velocity has opposite directions to the wave vectors.\\
For the Hole we thus find \[
E_h = E_0 + \frac{\hbar^2 k_h^2}{2m_h^*}
\] \[
\implies v_g^h = \frac{1}{\hbar } \frac{\partial E_h}{\partial k_h} = \frac{\hbar k_h}{m_h^*} = -\frac{\hbar k_e^2}{m_h^*}
.\]  The group velocity is the same for holes and electorns.
\section{Dynamics of Electors and Holes in the Bands}
We recall the equation of motion we used in the Drude model: \[
	\dot{\vec{p}} = \vec{F} - \frac{\vec{p}}{\tau}
\] 
For the electrons: $m_e^* \dot{\vec{v}_e} = -e\left( \vec{E} + \vec{v} \cross \vec{B} \right) - \frac{m_e^* \vec{v}}{\tau_e}$.\\
Fro holes we find: $m_h^* \dot{\vec{v}_h} = +e\left( \vec{E} + \vec{v} \cross \vec{B} \right) - \frac{m_h^* \vec{v}}{\tau_h}$ \\
If we substitude $m_h^* = - m_e^*$ we get the same equation of motion up to a sign. We can recall that the Drude model had trouble with the sign of the Hall coefficient and now we can see why - the sign of the Hall coefficient depends on wether the electronic transport takes place mainly by the electorns or by holes.\\
\section{Doping \& Temperature}
Let's consider the example of a Phosphorus atom in Si (as an example of a donor in a pure material). We saw that we can think of a P-atom as \[
	\text{"P"} = \text{"Si"} + 1 \text{ proton} + 1 \text{e}^{-1}
.\] We call P an "Hydrogenic" atom, adding one electron and one proton. \\
For a H atom we can calculate the binding energy to it's atom as: \[
E_\text{binding}= \frac{m_e e^4}{3 \epsilon_0^2 h^2} = Ry = 13.6 \text{eV}
.\] In a semiconductor we find instead \[
E_\text{binding} = \frac{m_e^* e^4}{8\left( \epsilon_0 \epsilon_r \right)^2 h^2} = \left( \frac{m_e^*}{m_e} \right) \left( \frac{1}{\epsilon_r^2} \right) Ry
.\] The binding energy is smaller in semiconductors. Since the binding energy is very small the donated electron is relatively "free", it therefore can jump to the conductance band at room temperatures (aka. we can ignore additional proton). Note: this is not true at very low temperatures.













\end{document}
